Building CIFAR-10 data loader with 1 workers
Files already downloaded and verified
CIFAR-10 training data size: 50000
Files already downloaded and verified
CIFAR-10 testing data size: 10000
=> creating model 'plainnet20'
Epoch: [0/80][0/250]	LR: 0.1	Time 1.876 (1.876)	Data 0.131 (0.131)	Loss 2.3701 (2.3701)	Prec@1 11.000 (11.000)
Epoch: [0/80][100/250]	LR: 0.1	Time 0.048 (0.063)	Data 0.031 (0.029)	Loss 1.6991 (1.9671)	Prec@1 35.000 (24.396)
Epoch: [0/80][200/250]	LR: 0.1	Time 0.041 (0.052)	Data 0.027 (0.027)	Loss 1.7050 (1.8354)	Prec@1 37.000 (30.189)
 * Training Prec@1 31.988
Test: [0/50]	Time 0.208 (0.208)	Loss 1.4344 (1.4344)	Prec@1 42.000 (42.000)
 * Testing Prec@1 40.820
Epoch: [1/80][0/250]	LR: 0.1	Time 0.238 (0.238)	Data 0.210 (0.210)	Loss 1.6053 (1.6053)	Prec@1 38.500 (38.500)
Epoch: [1/80][100/250]	LR: 0.1	Time 0.045 (0.043)	Data 0.029 (0.027)	Loss 1.5462 (1.4576)	Prec@1 47.500 (46.470)
Epoch: [1/80][200/250]	LR: 0.1	Time 0.042 (0.043)	Data 0.029 (0.027)	Loss 1.2699 (1.3787)	Prec@1 52.500 (49.353)
 * Training Prec@1 50.644
Test: [0/50]	Time 0.127 (0.127)	Loss 1.1997 (1.1997)	Prec@1 59.500 (59.500)
 * Testing Prec@1 53.130
Epoch: [2/80][0/250]	LR: 0.1	Time 0.247 (0.247)	Data 0.228 (0.228)	Loss 1.1536 (1.1536)	Prec@1 57.000 (57.000)
Epoch: [2/80][100/250]	LR: 0.1	Time 0.037 (0.044)	Data 0.022 (0.028)	Loss 0.9969 (1.1424)	Prec@1 67.000 (58.614)
Epoch: [2/80][200/250]	LR: 0.1	Time 0.047 (0.045)	Data 0.030 (0.029)	Loss 0.9568 (1.0986)	Prec@1 67.500 (60.363)
 * Training Prec@1 61.184
Test: [0/50]	Time 0.129 (0.129)	Loss 1.4650 (1.4650)	Prec@1 51.500 (51.500)
 * Testing Prec@1 53.110
Epoch: [3/80][0/250]	LR: 0.1	Time 0.263 (0.263)	Data 0.245 (0.245)	Loss 1.0120 (1.0120)	Prec@1 64.000 (64.000)
Epoch: [3/80][100/250]	LR: 0.1	Time 0.048 (0.046)	Data 0.030 (0.030)	Loss 0.9019 (0.9307)	Prec@1 67.000 (67.238)
Epoch: [3/80][200/250]	LR: 0.1	Time 0.046 (0.046)	Data 0.029 (0.029)	Loss 0.8501 (0.9026)	Prec@1 68.500 (68.353)
 * Training Prec@1 68.594
Test: [0/50]	Time 0.145 (0.145)	Loss 1.0412 (1.0412)	Prec@1 62.500 (62.500)
 * Testing Prec@1 59.840
Epoch: [4/80][0/250]	LR: 0.1	Time 0.260 (0.260)	Data 0.237 (0.237)	Loss 0.6895 (0.6895)	Prec@1 77.000 (77.000)
Epoch: [4/80][100/250]	LR: 0.1	Time 0.040 (0.045)	Data 0.027 (0.029)	Loss 0.8365 (0.8061)	Prec@1 73.500 (71.396)
Epoch: [4/80][200/250]	LR: 0.1	Time 0.039 (0.044)	Data 0.025 (0.028)	Loss 0.7590 (0.7979)	Prec@1 74.000 (71.913)
 * Training Prec@1 72.184
Test: [0/50]	Time 0.131 (0.131)	Loss 1.0898 (1.0898)	Prec@1 65.000 (65.000)
 * Testing Prec@1 64.360
Epoch: [5/80][0/250]	LR: 0.1	Time 0.201 (0.201)	Data 0.175 (0.175)	Loss 0.8244 (0.8244)	Prec@1 69.500 (69.500)
Epoch: [5/80][100/250]	LR: 0.1	Time 0.033 (0.045)	Data 0.017 (0.029)	Loss 0.7226 (0.7249)	Prec@1 74.500 (74.718)
Epoch: [5/80][200/250]	LR: 0.1	Time 0.037 (0.043)	Data 0.023 (0.028)	Loss 0.6693 (0.7239)	Prec@1 78.500 (74.796)
 * Training Prec@1 74.814
Test: [0/50]	Time 0.102 (0.102)	Loss 0.9763 (0.9763)	Prec@1 68.000 (68.000)
 * Testing Prec@1 67.250
Epoch: [6/80][0/250]	LR: 0.1	Time 0.262 (0.262)	Data 0.239 (0.239)	Loss 0.7463 (0.7463)	Prec@1 75.000 (75.000)
Epoch: [6/80][100/250]	LR: 0.1	Time 0.037 (0.044)	Data 0.020 (0.028)	Loss 0.5911 (0.6785)	Prec@1 80.000 (76.342)
Epoch: [6/80][200/250]	LR: 0.1	Time 0.037 (0.041)	Data 0.024 (0.025)	Loss 0.6465 (0.6684)	Prec@1 76.500 (76.706)
 * Training Prec@1 76.770
Test: [0/50]	Time 0.131 (0.131)	Loss 0.9073 (0.9073)	Prec@1 68.500 (68.500)
 * Testing Prec@1 68.100
Epoch: [7/80][0/250]	LR: 0.1	Time 0.126 (0.126)	Data 0.106 (0.106)	Loss 0.5561 (0.5561)	Prec@1 82.000 (82.000)
Epoch: [7/80][100/250]	LR: 0.1	Time 0.033 (0.039)	Data 0.018 (0.024)	Loss 0.6556 (0.6283)	Prec@1 77.000 (78.332)
Epoch: [7/80][200/250]	LR: 0.1	Time 0.032 (0.037)	Data 0.017 (0.023)	Loss 0.5923 (0.6283)	Prec@1 78.000 (78.174)
 * Training Prec@1 78.144
Test: [0/50]	Time 0.103 (0.103)	Loss 0.6931 (0.6931)	Prec@1 77.500 (77.500)
 * Testing Prec@1 73.550
Epoch: [8/80][0/250]	LR: 0.1	Time 0.138 (0.138)	Data 0.116 (0.116)	Loss 0.7349 (0.7349)	Prec@1 73.500 (73.500)
Epoch: [8/80][100/250]	LR: 0.1	Time 0.034 (0.037)	Data 0.021 (0.023)	Loss 0.6278 (0.6077)	Prec@1 78.500 (79.267)
Epoch: [8/80][200/250]	LR: 0.1	Time 0.034 (0.036)	Data 0.020 (0.022)	Loss 0.5994 (0.6017)	Prec@1 80.000 (79.480)
 * Training Prec@1 79.570
Test: [0/50]	Time 0.120 (0.120)	Loss 0.6200 (0.6200)	Prec@1 76.500 (76.500)
 * Testing Prec@1 74.790
Epoch: [9/80][0/250]	LR: 0.1	Time 0.177 (0.177)	Data 0.156 (0.156)	Loss 0.5397 (0.5397)	Prec@1 82.000 (82.000)
Epoch: [9/80][100/250]	LR: 0.1	Time 0.036 (0.042)	Data 0.022 (0.026)	Loss 0.6231 (0.5662)	Prec@1 78.000 (80.149)
Epoch: [9/80][200/250]	LR: 0.1	Time 0.036 (0.039)	Data 0.022 (0.024)	Loss 0.6007 (0.5672)	Prec@1 81.000 (80.209)
 * Training Prec@1 80.342
Test: [0/50]	Time 0.113 (0.113)	Loss 0.7014 (0.7014)	Prec@1 78.500 (78.500)
 * Testing Prec@1 77.530
Epoch: [10/80][0/250]	LR: 0.1	Time 0.132 (0.132)	Data 0.115 (0.115)	Loss 0.4905 (0.4905)	Prec@1 82.000 (82.000)
Epoch: [10/80][100/250]	LR: 0.1	Time 0.045 (0.037)	Data 0.029 (0.023)	Loss 0.5644 (0.5453)	Prec@1 81.000 (81.104)
Epoch: [10/80][200/250]	LR: 0.1	Time 0.034 (0.037)	Data 0.021 (0.023)	Loss 0.4859 (0.5393)	Prec@1 83.000 (81.284)
 * Training Prec@1 81.300
Test: [0/50]	Time 0.123 (0.123)	Loss 0.9943 (0.9943)	Prec@1 67.500 (67.500)
 * Testing Prec@1 72.360
Epoch: [11/80][0/250]	LR: 0.1	Time 0.228 (0.228)	Data 0.202 (0.202)	Loss 0.4905 (0.4905)	Prec@1 86.500 (86.500)
Epoch: [11/80][100/250]	LR: 0.1	Time 0.039 (0.041)	Data 0.025 (0.026)	Loss 0.5536 (0.5163)	Prec@1 78.500 (82.099)
Epoch: [11/80][200/250]	LR: 0.1	Time 0.040 (0.039)	Data 0.025 (0.024)	Loss 0.5443 (0.5206)	Prec@1 84.000 (82.045)
 * Training Prec@1 82.038
Test: [0/50]	Time 0.101 (0.101)	Loss 0.6995 (0.6995)	Prec@1 77.500 (77.500)
 * Testing Prec@1 74.860
Epoch: [12/80][0/250]	LR: 0.1	Time 0.207 (0.207)	Data 0.187 (0.187)	Loss 0.5221 (0.5221)	Prec@1 82.500 (82.500)
Epoch: [12/80][100/250]	LR: 0.1	Time 0.040 (0.042)	Data 0.024 (0.026)	Loss 0.4643 (0.4921)	Prec@1 86.000 (83.094)
Epoch: [12/80][200/250]	LR: 0.1	Time 0.035 (0.039)	Data 0.021 (0.024)	Loss 0.4261 (0.4945)	Prec@1 87.500 (82.925)
 * Training Prec@1 82.812
Test: [0/50]	Time 0.097 (0.097)	Loss 0.7193 (0.7193)	Prec@1 77.000 (77.000)
 * Testing Prec@1 77.240
Epoch: [13/80][0/250]	LR: 0.1	Time 0.200 (0.200)	Data 0.183 (0.183)	Loss 0.4729 (0.4729)	Prec@1 85.000 (85.000)
Epoch: [13/80][100/250]	LR: 0.1	Time 0.038 (0.038)	Data 0.024 (0.024)	Loss 0.5296 (0.4882)	Prec@1 81.500 (82.728)
Epoch: [13/80][200/250]	LR: 0.1	Time 0.036 (0.037)	Data 0.021 (0.023)	Loss 0.3726 (0.4888)	Prec@1 87.500 (82.831)
 * Training Prec@1 82.838
Test: [0/50]	Time 0.125 (0.125)	Loss 0.7835 (0.7835)	Prec@1 76.500 (76.500)
 * Testing Prec@1 75.370
Epoch: [14/80][0/250]	LR: 0.1	Time 0.198 (0.198)	Data 0.178 (0.178)	Loss 0.4491 (0.4491)	Prec@1 83.000 (83.000)
Epoch: [14/80][100/250]	LR: 0.1	Time 0.034 (0.041)	Data 0.022 (0.026)	Loss 0.6039 (0.4610)	Prec@1 78.000 (84.050)
Epoch: [14/80][200/250]	LR: 0.1	Time 0.049 (0.038)	Data 0.032 (0.023)	Loss 0.5012 (0.4649)	Prec@1 81.500 (83.888)
 * Training Prec@1 83.916
Test: [0/50]	Time 0.149 (0.149)	Loss 0.7265 (0.7265)	Prec@1 75.500 (75.500)
 * Testing Prec@1 77.770
Epoch: [15/80][0/250]	LR: 0.1	Time 0.188 (0.188)	Data 0.166 (0.166)	Loss 0.4708 (0.4708)	Prec@1 82.500 (82.500)
Epoch: [15/80][100/250]	LR: 0.1	Time 0.034 (0.039)	Data 0.020 (0.025)	Loss 0.3582 (0.4606)	Prec@1 87.000 (83.980)
Epoch: [15/80][200/250]	LR: 0.1	Time 0.033 (0.037)	Data 0.020 (0.023)	Loss 0.4141 (0.4578)	Prec@1 86.000 (84.112)
 * Training Prec@1 84.020
Test: [0/50]	Time 0.121 (0.121)	Loss 0.6609 (0.6609)	Prec@1 78.000 (78.000)
 * Testing Prec@1 79.720
Epoch: [16/80][0/250]	LR: 0.1	Time 0.133 (0.133)	Data 0.113 (0.113)	Loss 0.4836 (0.4836)	Prec@1 81.000 (81.000)
Epoch: [16/80][100/250]	LR: 0.1	Time 0.046 (0.037)	Data 0.022 (0.023)	Loss 0.4461 (0.4267)	Prec@1 86.500 (85.292)
Epoch: [16/80][200/250]	LR: 0.1	Time 0.038 (0.038)	Data 0.025 (0.023)	Loss 0.4150 (0.4351)	Prec@1 88.000 (85.055)
 * Training Prec@1 84.850
Test: [0/50]	Time 0.124 (0.124)	Loss 0.6180 (0.6180)	Prec@1 78.000 (78.000)
 * Testing Prec@1 80.850
Epoch: [17/80][0/250]	LR: 0.1	Time 0.201 (0.201)	Data 0.181 (0.181)	Loss 0.4253 (0.4253)	Prec@1 87.500 (87.500)
Epoch: [17/80][100/250]	LR: 0.1	Time 0.035 (0.036)	Data 0.022 (0.023)	Loss 0.4369 (0.4267)	Prec@1 84.500 (85.188)
Epoch: [17/80][200/250]	LR: 0.1	Time 0.038 (0.036)	Data 0.022 (0.023)	Loss 0.5028 (0.4308)	Prec@1 82.500 (85.104)
 * Training Prec@1 84.912
Test: [0/50]	Time 0.110 (0.110)	Loss 0.5451 (0.5451)	Prec@1 83.000 (83.000)
 * Testing Prec@1 80.620
Epoch: [18/80][0/250]	LR: 0.1	Time 0.210 (0.210)	Data 0.194 (0.194)	Loss 0.4391 (0.4391)	Prec@1 84.500 (84.500)
Epoch: [18/80][100/250]	LR: 0.1	Time 0.041 (0.038)	Data 0.025 (0.023)	Loss 0.6119 (0.4193)	Prec@1 80.500 (85.688)
Epoch: [18/80][200/250]	LR: 0.1	Time 0.034 (0.036)	Data 0.020 (0.021)	Loss 0.4198 (0.4271)	Prec@1 87.000 (85.246)
 * Training Prec@1 85.246
Test: [0/50]	Time 0.119 (0.119)	Loss 0.5971 (0.5971)	Prec@1 81.500 (81.500)
 * Testing Prec@1 81.630
Epoch: [19/80][0/250]	LR: 0.1	Time 0.180 (0.180)	Data 0.157 (0.157)	Loss 0.3816 (0.3816)	Prec@1 86.500 (86.500)
Epoch: [19/80][100/250]	LR: 0.1	Time 0.049 (0.040)	Data 0.031 (0.026)	Loss 0.4867 (0.4165)	Prec@1 82.000 (85.614)
Epoch: [19/80][200/250]	LR: 0.1	Time 0.039 (0.039)	Data 0.025 (0.024)	Loss 0.4449 (0.4192)	Prec@1 84.500 (85.552)
 * Training Prec@1 85.558
Test: [0/50]	Time 0.128 (0.128)	Loss 0.5805 (0.5805)	Prec@1 82.500 (82.500)
 * Testing Prec@1 82.640
Epoch: [20/80][0/250]	LR: 0.1	Time 0.150 (0.150)	Data 0.131 (0.131)	Loss 0.3999 (0.3999)	Prec@1 85.000 (85.000)
Epoch: [20/80][100/250]	LR: 0.1	Time 0.036 (0.043)	Data 0.021 (0.026)	Loss 0.3363 (0.3930)	Prec@1 88.000 (86.272)
Epoch: [20/80][200/250]	LR: 0.1	Time 0.035 (0.041)	Data 0.021 (0.025)	Loss 0.4083 (0.4058)	Prec@1 85.000 (85.881)
 * Training Prec@1 85.846
Test: [0/50]	Time 0.105 (0.105)	Loss 0.6650 (0.6650)	Prec@1 77.500 (77.500)
 * Testing Prec@1 80.850
Epoch: [21/80][0/250]	LR: 0.1	Time 0.148 (0.148)	Data 0.130 (0.130)	Loss 0.3807 (0.3807)	Prec@1 86.000 (86.000)
Epoch: [21/80][100/250]	LR: 0.1	Time 0.034 (0.038)	Data 0.021 (0.023)	Loss 0.3933 (0.3874)	Prec@1 89.500 (86.752)
Epoch: [21/80][200/250]	LR: 0.1	Time 0.035 (0.038)	Data 0.022 (0.023)	Loss 0.4279 (0.3975)	Prec@1 83.000 (86.264)
 * Training Prec@1 86.180
Test: [0/50]	Time 0.118 (0.118)	Loss 0.6470 (0.6470)	Prec@1 79.500 (79.500)
 * Testing Prec@1 81.590
Epoch: [22/80][0/250]	LR: 0.1	Time 0.446 (0.446)	Data 0.423 (0.423)	Loss 0.2633 (0.2633)	Prec@1 91.500 (91.500)
Epoch: [22/80][100/250]	LR: 0.1	Time 0.036 (0.042)	Data 0.022 (0.028)	Loss 0.4193 (0.3794)	Prec@1 86.000 (86.975)
Epoch: [22/80][200/250]	LR: 0.1	Time 0.036 (0.040)	Data 0.021 (0.025)	Loss 0.4410 (0.3906)	Prec@1 87.000 (86.495)
 * Training Prec@1 86.400
Test: [0/50]	Time 0.128 (0.128)	Loss 0.5497 (0.5497)	Prec@1 81.500 (81.500)
 * Testing Prec@1 81.250
Epoch: [23/80][0/250]	LR: 0.1	Time 0.213 (0.213)	Data 0.191 (0.191)	Loss 0.3950 (0.3950)	Prec@1 85.500 (85.500)
Epoch: [23/80][100/250]	LR: 0.1	Time 0.033 (0.040)	Data 0.021 (0.025)	Loss 0.3739 (0.3773)	Prec@1 85.500 (87.050)
Epoch: [23/80][200/250]	LR: 0.1	Time 0.034 (0.037)	Data 0.022 (0.023)	Loss 0.3060 (0.3787)	Prec@1 87.000 (87.002)
 * Training Prec@1 86.988
Test: [0/50]	Time 0.120 (0.120)	Loss 0.8025 (0.8025)	Prec@1 77.000 (77.000)
 * Testing Prec@1 76.170
Epoch: [24/80][0/250]	LR: 0.1	Time 0.260 (0.260)	Data 0.238 (0.238)	Loss 0.3691 (0.3691)	Prec@1 85.000 (85.000)
Epoch: [24/80][100/250]	LR: 0.1	Time 0.044 (0.045)	Data 0.029 (0.029)	Loss 0.2857 (0.3784)	Prec@1 91.500 (86.698)
Epoch: [24/80][200/250]	LR: 0.1	Time 0.035 (0.042)	Data 0.023 (0.027)	Loss 0.3025 (0.3771)	Prec@1 90.000 (86.719)
 * Training Prec@1 86.672
Test: [0/50]	Time 0.107 (0.107)	Loss 0.5751 (0.5751)	Prec@1 82.500 (82.500)
 * Testing Prec@1 81.390
Epoch: [25/80][0/250]	LR: 0.1	Time 0.160 (0.160)	Data 0.145 (0.145)	Loss 0.3418 (0.3418)	Prec@1 90.000 (90.000)
Epoch: [25/80][100/250]	LR: 0.1	Time 0.034 (0.039)	Data 0.020 (0.024)	Loss 0.3578 (0.3701)	Prec@1 84.000 (87.317)
Epoch: [25/80][200/250]	LR: 0.1	Time 0.035 (0.037)	Data 0.021 (0.023)	Loss 0.2781 (0.3737)	Prec@1 89.000 (87.137)
 * Training Prec@1 87.092
Test: [0/50]	Time 0.121 (0.121)	Loss 0.5935 (0.5935)	Prec@1 79.000 (79.000)
 * Testing Prec@1 81.140
Epoch: [26/80][0/250]	LR: 0.1	Time 0.287 (0.287)	Data 0.262 (0.262)	Loss 0.3090 (0.3090)	Prec@1 89.000 (89.000)
Epoch: [26/80][100/250]	LR: 0.1	Time 0.033 (0.038)	Data 0.021 (0.024)	Loss 0.4193 (0.3607)	Prec@1 85.000 (87.436)
Epoch: [26/80][200/250]	LR: 0.1	Time 0.034 (0.036)	Data 0.020 (0.023)	Loss 0.4018 (0.3589)	Prec@1 86.000 (87.585)
 * Training Prec@1 87.448
Test: [0/50]	Time 0.120 (0.120)	Loss 0.5333 (0.5333)	Prec@1 80.000 (80.000)
 * Testing Prec@1 83.300
Epoch: [27/80][0/250]	LR: 0.1	Time 0.244 (0.244)	Data 0.224 (0.224)	Loss 0.2817 (0.2817)	Prec@1 88.500 (88.500)
Epoch: [27/80][100/250]	LR: 0.1	Time 0.033 (0.037)	Data 0.018 (0.022)	Loss 0.3181 (0.3458)	Prec@1 89.500 (88.000)
Epoch: [27/80][200/250]	LR: 0.1	Time 0.038 (0.037)	Data 0.022 (0.022)	Loss 0.5712 (0.3567)	Prec@1 82.500 (87.614)
 * Training Prec@1 87.582
Test: [0/50]	Time 0.125 (0.125)	Loss 0.5348 (0.5348)	Prec@1 82.000 (82.000)
 * Testing Prec@1 82.350
Epoch: [28/80][0/250]	LR: 0.1	Time 0.235 (0.235)	Data 0.217 (0.217)	Loss 0.2803 (0.2803)	Prec@1 90.000 (90.000)
Epoch: [28/80][100/250]	LR: 0.1	Time 0.034 (0.038)	Data 0.021 (0.024)	Loss 0.2695 (0.3490)	Prec@1 92.500 (87.896)
Epoch: [28/80][200/250]	LR: 0.1	Time 0.034 (0.037)	Data 0.021 (0.023)	Loss 0.3443 (0.3496)	Prec@1 89.500 (87.799)
 * Training Prec@1 87.778
Test: [0/50]	Time 0.120 (0.120)	Loss 0.5769 (0.5769)	Prec@1 84.500 (84.500)
 * Testing Prec@1 82.150
Epoch: [29/80][0/250]	LR: 0.1	Time 0.224 (0.224)	Data 0.205 (0.205)	Loss 0.3657 (0.3657)	Prec@1 87.500 (87.500)
Epoch: [29/80][100/250]	LR: 0.1	Time 0.034 (0.038)	Data 0.020 (0.023)	Loss 0.3558 (0.3397)	Prec@1 86.000 (88.193)
Epoch: [29/80][200/250]	LR: 0.1	Time 0.035 (0.038)	Data 0.021 (0.023)	Loss 0.2964 (0.3448)	Prec@1 89.500 (88.070)
 * Training Prec@1 87.898
Test: [0/50]	Time 0.132 (0.132)	Loss 0.4421 (0.4421)	Prec@1 85.500 (85.500)
 * Testing Prec@1 83.270
Epoch: [30/80][0/250]	LR: 0.1	Time 0.239 (0.239)	Data 0.217 (0.217)	Loss 0.2881 (0.2881)	Prec@1 90.000 (90.000)
Epoch: [30/80][100/250]	LR: 0.1	Time 0.035 (0.047)	Data 0.022 (0.030)	Loss 0.3527 (0.3371)	Prec@1 87.000 (88.510)
Epoch: [30/80][200/250]	LR: 0.1	Time 0.040 (0.042)	Data 0.022 (0.026)	Loss 0.3521 (0.3425)	Prec@1 88.500 (88.224)
 * Training Prec@1 88.228
Test: [0/50]	Time 0.120 (0.120)	Loss 0.5194 (0.5194)	Prec@1 84.500 (84.500)
 * Testing Prec@1 81.790
Epoch: [31/80][0/250]	LR: 0.1	Time 0.263 (0.263)	Data 0.239 (0.239)	Loss 0.3817 (0.3817)	Prec@1 88.000 (88.000)
Epoch: [31/80][100/250]	LR: 0.1	Time 0.042 (0.040)	Data 0.025 (0.024)	Loss 0.3790 (0.3435)	Prec@1 86.000 (88.000)
Epoch: [31/80][200/250]	LR: 0.1	Time 0.036 (0.037)	Data 0.023 (0.022)	Loss 0.3041 (0.3420)	Prec@1 90.500 (88.159)
 * Training Prec@1 88.134
Test: [0/50]	Time 0.115 (0.115)	Loss 0.5089 (0.5089)	Prec@1 85.500 (85.500)
 * Testing Prec@1 81.990
Epoch: [32/80][0/250]	LR: 0.1	Time 0.251 (0.251)	Data 0.229 (0.229)	Loss 0.2769 (0.2769)	Prec@1 90.000 (90.000)
Epoch: [32/80][100/250]	LR: 0.1	Time 0.036 (0.041)	Data 0.022 (0.026)	Loss 0.2807 (0.3339)	Prec@1 89.500 (88.361)
Epoch: [32/80][200/250]	LR: 0.1	Time 0.037 (0.038)	Data 0.023 (0.024)	Loss 0.3066 (0.3369)	Prec@1 89.000 (88.376)
 * Training Prec@1 88.264
Test: [0/50]	Time 0.127 (0.127)	Loss 0.5010 (0.5010)	Prec@1 83.500 (83.500)
 * Testing Prec@1 81.260
Epoch: [33/80][0/250]	LR: 0.1	Time 0.207 (0.207)	Data 0.187 (0.187)	Loss 0.3440 (0.3440)	Prec@1 86.500 (86.500)
Epoch: [33/80][100/250]	LR: 0.1	Time 0.036 (0.039)	Data 0.023 (0.024)	Loss 0.3609 (0.3137)	Prec@1 85.500 (89.020)
Epoch: [33/80][200/250]	LR: 0.1	Time 0.034 (0.037)	Data 0.021 (0.023)	Loss 0.3583 (0.3232)	Prec@1 87.000 (88.597)
 * Training Prec@1 88.382
Test: [0/50]	Time 0.134 (0.134)	Loss 0.5688 (0.5688)	Prec@1 83.500 (83.500)
 * Testing Prec@1 81.770
Epoch: [34/80][0/250]	LR: 0.1	Time 0.270 (0.270)	Data 0.249 (0.249)	Loss 0.3502 (0.3502)	Prec@1 85.500 (85.500)
Epoch: [34/80][100/250]	LR: 0.1	Time 0.033 (0.040)	Data 0.018 (0.025)	Loss 0.2807 (0.3191)	Prec@1 90.500 (89.025)
Epoch: [34/80][200/250]	LR: 0.1	Time 0.035 (0.038)	Data 0.021 (0.023)	Loss 0.3984 (0.3225)	Prec@1 86.000 (88.878)
 * Training Prec@1 88.730
Test: [0/50]	Time 0.159 (0.159)	Loss 0.5289 (0.5289)	Prec@1 85.500 (85.500)
 * Testing Prec@1 83.340
Epoch: [35/80][0/250]	LR: 0.1	Time 0.182 (0.182)	Data 0.148 (0.148)	Loss 0.2564 (0.2564)	Prec@1 89.500 (89.500)
Epoch: [35/80][100/250]	LR: 0.1	Time 0.037 (0.040)	Data 0.025 (0.026)	Loss 0.2849 (0.3156)	Prec@1 88.500 (89.129)
Epoch: [35/80][200/250]	LR: 0.1	Time 0.035 (0.038)	Data 0.020 (0.024)	Loss 0.3081 (0.3193)	Prec@1 89.500 (88.861)
 * Training Prec@1 88.886
Test: [0/50]	Time 0.133 (0.133)	Loss 0.5405 (0.5405)	Prec@1 82.500 (82.500)
 * Testing Prec@1 81.330
Epoch: [36/80][0/250]	LR: 0.1	Time 0.246 (0.246)	Data 0.227 (0.227)	Loss 0.4162 (0.4162)	Prec@1 86.500 (86.500)
Epoch: [36/80][100/250]	LR: 0.1	Time 0.032 (0.040)	Data 0.018 (0.025)	Loss 0.3248 (0.3120)	Prec@1 89.000 (89.376)
Epoch: [36/80][200/250]	LR: 0.1	Time 0.037 (0.038)	Data 0.021 (0.024)	Loss 0.2918 (0.3209)	Prec@1 89.000 (89.062)
 * Training Prec@1 89.020
Test: [0/50]	Time 0.109 (0.109)	Loss 0.4602 (0.4602)	Prec@1 84.500 (84.500)
 * Testing Prec@1 83.950
Epoch: [37/80][0/250]	LR: 0.1	Time 0.187 (0.187)	Data 0.170 (0.170)	Loss 0.3205 (0.3205)	Prec@1 86.500 (86.500)
Epoch: [37/80][100/250]	LR: 0.1	Time 0.035 (0.041)	Data 0.021 (0.026)	Loss 0.3170 (0.3133)	Prec@1 89.000 (88.906)
Epoch: [37/80][200/250]	LR: 0.1	Time 0.039 (0.039)	Data 0.026 (0.025)	Loss 0.3433 (0.3193)	Prec@1 87.500 (88.714)
 * Training Prec@1 88.750
Test: [0/50]	Time 0.110 (0.110)	Loss 0.4603 (0.4603)	Prec@1 84.000 (84.000)
 * Testing Prec@1 83.910
Epoch: [38/80][0/250]	LR: 0.1	Time 0.216 (0.216)	Data 0.196 (0.196)	Loss 0.2024 (0.2024)	Prec@1 95.000 (95.000)
Epoch: [38/80][100/250]	LR: 0.1	Time 0.036 (0.040)	Data 0.023 (0.025)	Loss 0.4298 (0.2920)	Prec@1 85.000 (89.891)
Epoch: [38/80][200/250]	LR: 0.1	Time 0.045 (0.038)	Data 0.026 (0.024)	Loss 0.1711 (0.3062)	Prec@1 94.000 (89.321)
 * Training Prec@1 89.132
Test: [0/50]	Time 0.113 (0.113)	Loss 0.5998 (0.5998)	Prec@1 81.000 (81.000)
 * Testing Prec@1 81.980
Epoch: [39/80][0/250]	LR: 0.1	Time 0.207 (0.207)	Data 0.187 (0.187)	Loss 0.2258 (0.2258)	Prec@1 92.500 (92.500)
Epoch: [39/80][100/250]	LR: 0.1	Time 0.036 (0.040)	Data 0.021 (0.025)	Loss 0.4033 (0.3073)	Prec@1 83.000 (89.144)
Epoch: [39/80][200/250]	LR: 0.1	Time 0.037 (0.039)	Data 0.023 (0.025)	Loss 0.2660 (0.3092)	Prec@1 90.500 (89.177)
 * Training Prec@1 89.110
Test: [0/50]	Time 0.120 (0.120)	Loss 0.4558 (0.4558)	Prec@1 84.500 (84.500)
 * Testing Prec@1 84.060
Epoch: [40/80][0/250]	LR: 0.01	Time 0.191 (0.191)	Data 0.169 (0.169)	Loss 0.3626 (0.3626)	Prec@1 87.000 (87.000)
Epoch: [40/80][100/250]	LR: 0.01	Time 0.042 (0.040)	Data 0.026 (0.025)	Loss 0.2604 (0.2526)	Prec@1 90.000 (91.168)
Epoch: [40/80][200/250]	LR: 0.01	Time 0.038 (0.041)	Data 0.022 (0.026)	Loss 0.2550 (0.2344)	Prec@1 91.000 (91.933)
 * Training Prec@1 92.038
Test: [0/50]	Time 0.140 (0.140)	Loss 0.2799 (0.2799)	Prec@1 91.000 (91.000)
 * Testing Prec@1 88.250
Epoch: [41/80][0/250]	LR: 0.01	Time 0.173 (0.173)	Data 0.158 (0.158)	Loss 0.1483 (0.1483)	Prec@1 94.000 (94.000)
Epoch: [41/80][100/250]	LR: 0.01	Time 0.045 (0.047)	Data 0.028 (0.030)	Loss 0.1890 (0.1922)	Prec@1 92.500 (93.460)
Epoch: [41/80][200/250]	LR: 0.01	Time 0.039 (0.043)	Data 0.024 (0.027)	Loss 0.1702 (0.1921)	Prec@1 95.000 (93.433)
 * Training Prec@1 93.378
Test: [0/50]	Time 0.112 (0.112)	Loss 0.2681 (0.2681)	Prec@1 90.000 (90.000)
 * Testing Prec@1 88.610
Epoch: [42/80][0/250]	LR: 0.01	Time 0.263 (0.263)	Data 0.242 (0.242)	Loss 0.1731 (0.1731)	Prec@1 95.000 (95.000)
Epoch: [42/80][100/250]	LR: 0.01	Time 0.035 (0.043)	Data 0.021 (0.026)	Loss 0.2323 (0.1854)	Prec@1 91.500 (93.718)
Epoch: [42/80][200/250]	LR: 0.01	Time 0.036 (0.042)	Data 0.023 (0.026)	Loss 0.1431 (0.1839)	Prec@1 93.500 (93.731)
 * Training Prec@1 93.740
Test: [0/50]	Time 0.146 (0.146)	Loss 0.2621 (0.2621)	Prec@1 90.500 (90.500)
 * Testing Prec@1 88.890
Epoch: [43/80][0/250]	LR: 0.01	Time 0.257 (0.257)	Data 0.235 (0.235)	Loss 0.1421 (0.1421)	Prec@1 94.000 (94.000)
Epoch: [43/80][100/250]	LR: 0.01	Time 0.038 (0.045)	Data 0.025 (0.029)	Loss 0.2347 (0.1768)	Prec@1 93.000 (94.094)
Epoch: [43/80][200/250]	LR: 0.01	Time 0.033 (0.040)	Data 0.021 (0.025)	Loss 0.1892 (0.1808)	Prec@1 93.500 (93.863)
 * Training Prec@1 93.942
Test: [0/50]	Time 0.123 (0.123)	Loss 0.2523 (0.2523)	Prec@1 89.500 (89.500)
 * Testing Prec@1 89.090
Epoch: [44/80][0/250]	LR: 0.01	Time 0.193 (0.193)	Data 0.176 (0.176)	Loss 0.1752 (0.1752)	Prec@1 93.500 (93.500)
Epoch: [44/80][100/250]	LR: 0.01	Time 0.040 (0.039)	Data 0.026 (0.025)	Loss 0.1711 (0.1679)	Prec@1 93.500 (94.059)
Epoch: [44/80][200/250]	LR: 0.01	Time 0.035 (0.039)	Data 0.020 (0.024)	Loss 0.1274 (0.1685)	Prec@1 95.000 (94.139)
 * Training Prec@1 94.108
Test: [0/50]	Time 0.102 (0.102)	Loss 0.2608 (0.2608)	Prec@1 91.500 (91.500)
 * Testing Prec@1 88.820
Epoch: [45/80][0/250]	LR: 0.01	Time 0.227 (0.227)	Data 0.207 (0.207)	Loss 0.1494 (0.1494)	Prec@1 93.500 (93.500)
Epoch: [45/80][100/250]	LR: 0.01	Time 0.033 (0.038)	Data 0.020 (0.024)	Loss 0.1408 (0.1644)	Prec@1 95.500 (94.376)
Epoch: [45/80][200/250]	LR: 0.01	Time 0.049 (0.039)	Data 0.032 (0.024)	Loss 0.1577 (0.1660)	Prec@1 96.500 (94.311)
 * Training Prec@1 94.278
Test: [0/50]	Time 0.091 (0.091)	Loss 0.2491 (0.2491)	Prec@1 92.000 (92.000)
 * Testing Prec@1 89.130
Epoch: [46/80][0/250]	LR: 0.01	Time 0.137 (0.137)	Data 0.123 (0.123)	Loss 0.1647 (0.1647)	Prec@1 94.500 (94.500)
Epoch: [46/80][100/250]	LR: 0.01	Time 0.035 (0.036)	Data 0.020 (0.022)	Loss 0.1332 (0.1592)	Prec@1 94.500 (94.530)
Epoch: [46/80][200/250]	LR: 0.01	Time 0.035 (0.037)	Data 0.023 (0.023)	Loss 0.1093 (0.1611)	Prec@1 97.000 (94.480)
 * Training Prec@1 94.474
Test: [0/50]	Time 0.097 (0.097)	Loss 0.2441 (0.2441)	Prec@1 91.000 (91.000)
 * Testing Prec@1 89.050
Epoch: [47/80][0/250]	LR: 0.01	Time 0.204 (0.204)	Data 0.185 (0.185)	Loss 0.1341 (0.1341)	Prec@1 97.000 (97.000)
Epoch: [47/80][100/250]	LR: 0.01	Time 0.037 (0.043)	Data 0.021 (0.028)	Loss 0.2118 (0.1486)	Prec@1 93.000 (94.738)
Epoch: [47/80][200/250]	LR: 0.01	Time 0.036 (0.043)	Data 0.022 (0.027)	Loss 0.2122 (0.1525)	Prec@1 93.500 (94.697)
 * Training Prec@1 94.608
Test: [0/50]	Time 0.089 (0.089)	Loss 0.2569 (0.2569)	Prec@1 90.500 (90.500)
 * Testing Prec@1 88.900
Epoch: [48/80][0/250]	LR: 0.01	Time 0.237 (0.237)	Data 0.222 (0.222)	Loss 0.1808 (0.1808)	Prec@1 93.500 (93.500)
Epoch: [48/80][100/250]	LR: 0.01	Time 0.037 (0.037)	Data 0.022 (0.023)	Loss 0.1828 (0.1524)	Prec@1 95.500 (94.708)
Epoch: [48/80][200/250]	LR: 0.01	Time 0.045 (0.038)	Data 0.028 (0.024)	Loss 0.1068 (0.1541)	Prec@1 97.000 (94.714)
 * Training Prec@1 94.676
Test: [0/50]	Time 0.130 (0.130)	Loss 0.2471 (0.2471)	Prec@1 92.000 (92.000)
 * Testing Prec@1 88.680
Epoch: [49/80][0/250]	LR: 0.01	Time 0.244 (0.244)	Data 0.226 (0.226)	Loss 0.1363 (0.1363)	Prec@1 95.000 (95.000)
Epoch: [49/80][100/250]	LR: 0.01	Time 0.036 (0.043)	Data 0.020 (0.027)	Loss 0.1239 (0.1469)	Prec@1 94.500 (94.837)
Epoch: [49/80][200/250]	LR: 0.01	Time 0.036 (0.040)	Data 0.022 (0.025)	Loss 0.1659 (0.1484)	Prec@1 93.500 (94.724)
 * Training Prec@1 94.650
Test: [0/50]	Time 0.091 (0.091)	Loss 0.2549 (0.2549)	Prec@1 91.500 (91.500)
 * Testing Prec@1 88.620
Epoch: [50/80][0/250]	LR: 0.01	Time 0.185 (0.185)	Data 0.170 (0.170)	Loss 0.1286 (0.1286)	Prec@1 93.500 (93.500)
Epoch: [50/80][100/250]	LR: 0.01	Time 0.035 (0.038)	Data 0.022 (0.024)	Loss 0.1561 (0.1500)	Prec@1 96.000 (94.886)
Epoch: [50/80][200/250]	LR: 0.01	Time 0.035 (0.037)	Data 0.022 (0.023)	Loss 0.1387 (0.1461)	Prec@1 95.000 (95.000)
 * Training Prec@1 94.898
Test: [0/50]	Time 0.118 (0.118)	Loss 0.2555 (0.2555)	Prec@1 91.500 (91.500)
 * Testing Prec@1 89.010
Epoch: [51/80][0/250]	LR: 0.01	Time 0.199 (0.199)	Data 0.175 (0.175)	Loss 0.1491 (0.1491)	Prec@1 95.000 (95.000)
Epoch: [51/80][100/250]	LR: 0.01	Time 0.036 (0.040)	Data 0.022 (0.025)	Loss 0.1547 (0.1420)	Prec@1 93.000 (94.926)
Epoch: [51/80][200/250]	LR: 0.01	Time 0.035 (0.038)	Data 0.022 (0.023)	Loss 0.1310 (0.1425)	Prec@1 94.500 (95.040)
 * Training Prec@1 95.080
Test: [0/50]	Time 0.117 (0.117)	Loss 0.2578 (0.2578)	Prec@1 91.500 (91.500)
 * Testing Prec@1 88.870
Epoch: [52/80][0/250]	LR: 0.01	Time 0.198 (0.198)	Data 0.179 (0.179)	Loss 0.1313 (0.1313)	Prec@1 96.000 (96.000)
Epoch: [52/80][100/250]	LR: 0.01	Time 0.033 (0.036)	Data 0.020 (0.023)	Loss 0.1472 (0.1391)	Prec@1 93.500 (95.020)
Epoch: [52/80][200/250]	LR: 0.01	Time 0.033 (0.036)	Data 0.018 (0.022)	Loss 0.1747 (0.1420)	Prec@1 93.000 (95.012)
 * Training Prec@1 95.090
Test: [0/50]	Time 0.129 (0.129)	Loss 0.2504 (0.2504)	Prec@1 92.000 (92.000)
 * Testing Prec@1 88.840
Epoch: [53/80][0/250]	LR: 0.01	Time 0.227 (0.227)	Data 0.206 (0.206)	Loss 0.0805 (0.0805)	Prec@1 98.000 (98.000)
Epoch: [53/80][100/250]	LR: 0.01	Time 0.036 (0.036)	Data 0.022 (0.022)	Loss 0.1657 (0.1365)	Prec@1 94.000 (95.322)
Epoch: [53/80][200/250]	LR: 0.01	Time 0.033 (0.035)	Data 0.020 (0.021)	Loss 0.1656 (0.1385)	Prec@1 94.000 (95.144)
 * Training Prec@1 95.190
Test: [0/50]	Time 0.094 (0.094)	Loss 0.2675 (0.2675)	Prec@1 92.000 (92.000)
 * Testing Prec@1 88.840
Epoch: [54/80][0/250]	LR: 0.01	Time 0.227 (0.227)	Data 0.211 (0.211)	Loss 0.1430 (0.1430)	Prec@1 94.000 (94.000)
Epoch: [54/80][100/250]	LR: 0.01	Time 0.036 (0.040)	Data 0.021 (0.024)	Loss 0.1166 (0.1334)	Prec@1 95.500 (95.282)
Epoch: [54/80][200/250]	LR: 0.01	Time 0.035 (0.037)	Data 0.018 (0.022)	Loss 0.1501 (0.1329)	Prec@1 96.000 (95.336)
 * Training Prec@1 95.250
Test: [0/50]	Time 0.132 (0.132)	Loss 0.2979 (0.2979)	Prec@1 91.000 (91.000)
 * Testing Prec@1 88.810
Epoch: [55/80][0/250]	LR: 0.01	Time 0.253 (0.253)	Data 0.232 (0.232)	Loss 0.0886 (0.0886)	Prec@1 96.500 (96.500)
Epoch: [55/80][100/250]	LR: 0.01	Time 0.033 (0.037)	Data 0.020 (0.024)	Loss 0.2003 (0.1262)	Prec@1 93.000 (95.683)
Epoch: [55/80][200/250]	LR: 0.01	Time 0.035 (0.037)	Data 0.021 (0.023)	Loss 0.1459 (0.1323)	Prec@1 96.500 (95.378)
 * Training Prec@1 95.398
Test: [0/50]	Time 0.118 (0.118)	Loss 0.2681 (0.2681)	Prec@1 90.500 (90.500)
 * Testing Prec@1 88.850
Epoch: [56/80][0/250]	LR: 0.01	Time 0.256 (0.256)	Data 0.234 (0.234)	Loss 0.1582 (0.1582)	Prec@1 95.000 (95.000)
Epoch: [56/80][100/250]	LR: 0.01	Time 0.034 (0.037)	Data 0.019 (0.022)	Loss 0.1319 (0.1297)	Prec@1 95.500 (95.550)
Epoch: [56/80][200/250]	LR: 0.01	Time 0.035 (0.036)	Data 0.020 (0.022)	Loss 0.1616 (0.1294)	Prec@1 92.500 (95.463)
 * Training Prec@1 95.442
Test: [0/50]	Time 0.121 (0.121)	Loss 0.2691 (0.2691)	Prec@1 91.500 (91.500)
 * Testing Prec@1 88.650
Epoch: [57/80][0/250]	LR: 0.01	Time 0.218 (0.218)	Data 0.194 (0.194)	Loss 0.1241 (0.1241)	Prec@1 95.500 (95.500)
Epoch: [57/80][100/250]	LR: 0.01	Time 0.034 (0.039)	Data 0.021 (0.024)	Loss 0.1386 (0.1288)	Prec@1 95.500 (95.490)
Epoch: [57/80][200/250]	LR: 0.01	Time 0.043 (0.038)	Data 0.025 (0.023)	Loss 0.1529 (0.1318)	Prec@1 95.000 (95.391)
 * Training Prec@1 95.352
Test: [0/50]	Time 0.128 (0.128)	Loss 0.2840 (0.2840)	Prec@1 91.000 (91.000)
 * Testing Prec@1 88.430
Epoch: [58/80][0/250]	LR: 0.01	Time 0.238 (0.238)	Data 0.221 (0.221)	Loss 0.1104 (0.1104)	Prec@1 96.000 (96.000)
Epoch: [58/80][100/250]	LR: 0.01	Time 0.034 (0.037)	Data 0.019 (0.022)	Loss 0.0964 (0.1240)	Prec@1 97.000 (95.639)
Epoch: [58/80][200/250]	LR: 0.01	Time 0.044 (0.036)	Data 0.030 (0.021)	Loss 0.1515 (0.1256)	Prec@1 95.000 (95.565)
 * Training Prec@1 95.584
Test: [0/50]	Time 0.093 (0.093)	Loss 0.2519 (0.2519)	Prec@1 92.000 (92.000)
 * Testing Prec@1 88.740
Epoch: [59/80][0/250]	LR: 0.01	Time 0.248 (0.248)	Data 0.228 (0.228)	Loss 0.1106 (0.1106)	Prec@1 95.500 (95.500)
Epoch: [59/80][100/250]	LR: 0.01	Time 0.034 (0.039)	Data 0.019 (0.024)	Loss 0.1404 (0.1246)	Prec@1 96.000 (95.658)
Epoch: [59/80][200/250]	LR: 0.01	Time 0.035 (0.038)	Data 0.022 (0.023)	Loss 0.0961 (0.1247)	Prec@1 96.500 (95.595)
 * Training Prec@1 95.586
Test: [0/50]	Time 0.121 (0.121)	Loss 0.2793 (0.2793)	Prec@1 91.500 (91.500)
 * Testing Prec@1 88.790
Epoch: [60/80][0/250]	LR: 0.001	Time 0.231 (0.231)	Data 0.211 (0.211)	Loss 0.1469 (0.1469)	Prec@1 95.500 (95.500)
Epoch: [60/80][100/250]	LR: 0.001	Time 0.035 (0.038)	Data 0.022 (0.024)	Loss 0.0958 (0.1136)	Prec@1 97.000 (96.094)
Epoch: [60/80][200/250]	LR: 0.001	Time 0.036 (0.039)	Data 0.023 (0.025)	Loss 0.1063 (0.1166)	Prec@1 96.000 (95.920)
 * Training Prec@1 95.926
Test: [0/50]	Time 0.124 (0.124)	Loss 0.2855 (0.2855)	Prec@1 90.500 (90.500)
 * Testing Prec@1 88.870
Epoch: [61/80][0/250]	LR: 0.001	Time 0.245 (0.245)	Data 0.224 (0.224)	Loss 0.1673 (0.1673)	Prec@1 95.500 (95.500)
Epoch: [61/80][100/250]	LR: 0.001	Time 0.037 (0.042)	Data 0.020 (0.025)	Loss 0.0770 (0.1125)	Prec@1 96.500 (96.153)
Epoch: [61/80][200/250]	LR: 0.001	Time 0.038 (0.038)	Data 0.023 (0.022)	Loss 0.1284 (0.1133)	Prec@1 94.000 (96.087)
 * Training Prec@1 96.078
Test: [0/50]	Time 0.114 (0.114)	Loss 0.2730 (0.2730)	Prec@1 90.000 (90.000)
 * Testing Prec@1 88.940
Epoch: [62/80][0/250]	LR: 0.001	Time 0.259 (0.259)	Data 0.234 (0.234)	Loss 0.1167 (0.1167)	Prec@1 96.500 (96.500)
Epoch: [62/80][100/250]	LR: 0.001	Time 0.034 (0.041)	Data 0.021 (0.025)	Loss 0.0697 (0.1099)	Prec@1 98.000 (96.257)
Epoch: [62/80][200/250]	LR: 0.001	Time 0.035 (0.038)	Data 0.020 (0.023)	Loss 0.0884 (0.1106)	Prec@1 97.500 (96.231)
 * Training Prec@1 96.214
Test: [0/50]	Time 0.129 (0.129)	Loss 0.2767 (0.2767)	Prec@1 91.000 (91.000)
 * Testing Prec@1 89.020
Epoch: [63/80][0/250]	LR: 0.001	Time 0.269 (0.269)	Data 0.247 (0.247)	Loss 0.0864 (0.0864)	Prec@1 97.000 (97.000)
Epoch: [63/80][100/250]	LR: 0.001	Time 0.038 (0.039)	Data 0.023 (0.024)	Loss 0.1051 (0.1102)	Prec@1 97.000 (96.267)
Epoch: [63/80][200/250]	LR: 0.001	Time 0.033 (0.038)	Data 0.017 (0.023)	Loss 0.1138 (0.1110)	Prec@1 95.000 (96.192)
 * Training Prec@1 96.240
Test: [0/50]	Time 0.120 (0.120)	Loss 0.2762 (0.2762)	Prec@1 91.000 (91.000)
 * Testing Prec@1 89.090
Epoch: [64/80][0/250]	LR: 0.001	Time 0.241 (0.241)	Data 0.220 (0.220)	Loss 0.0923 (0.0923)	Prec@1 96.500 (96.500)
Epoch: [64/80][100/250]	LR: 0.001	Time 0.032 (0.041)	Data 0.017 (0.026)	Loss 0.0897 (0.1125)	Prec@1 98.000 (96.163)
Epoch: [64/80][200/250]	LR: 0.001	Time 0.037 (0.040)	Data 0.022 (0.024)	Loss 0.0933 (0.1107)	Prec@1 97.000 (96.197)
 * Training Prec@1 96.208
Test: [0/50]	Time 0.116 (0.116)	Loss 0.2753 (0.2753)	Prec@1 90.500 (90.500)
 * Testing Prec@1 88.910
Epoch: [65/80][0/250]	LR: 0.001	Time 0.217 (0.217)	Data 0.198 (0.198)	Loss 0.0694 (0.0694)	Prec@1 98.000 (98.000)
Epoch: [65/80][100/250]	LR: 0.001	Time 0.037 (0.040)	Data 0.023 (0.025)	Loss 0.0974 (0.1108)	Prec@1 96.500 (96.257)
Epoch: [65/80][200/250]	LR: 0.001	Time 0.038 (0.039)	Data 0.024 (0.024)	Loss 0.0770 (0.1101)	Prec@1 97.000 (96.244)
 * Training Prec@1 96.244
Test: [0/50]	Time 0.130 (0.130)	Loss 0.2699 (0.2699)	Prec@1 90.500 (90.500)
 * Testing Prec@1 88.930
Epoch: [66/80][0/250]	LR: 0.001	Time 0.218 (0.218)	Data 0.199 (0.199)	Loss 0.0818 (0.0818)	Prec@1 98.000 (98.000)
Epoch: [66/80][100/250]	LR: 0.001	Time 0.036 (0.040)	Data 0.023 (0.026)	Loss 0.0658 (0.1072)	Prec@1 98.500 (96.480)
Epoch: [66/80][200/250]	LR: 0.001	Time 0.037 (0.038)	Data 0.025 (0.024)	Loss 0.0756 (0.1079)	Prec@1 98.500 (96.326)
 * Training Prec@1 96.298
Test: [0/50]	Time 0.115 (0.115)	Loss 0.2749 (0.2749)	Prec@1 90.500 (90.500)
 * Testing Prec@1 88.920
Epoch: [67/80][0/250]	LR: 0.001	Time 0.226 (0.226)	Data 0.207 (0.207)	Loss 0.0734 (0.0734)	Prec@1 98.500 (98.500)
Epoch: [67/80][100/250]	LR: 0.001	Time 0.038 (0.040)	Data 0.023 (0.026)	Loss 0.0554 (0.1098)	Prec@1 98.500 (96.089)
Epoch: [67/80][200/250]	LR: 0.001	Time 0.035 (0.038)	Data 0.021 (0.024)	Loss 0.1073 (0.1121)	Prec@1 97.000 (96.020)
 * Training Prec@1 96.086
Test: [0/50]	Time 0.139 (0.139)	Loss 0.2687 (0.2687)	Prec@1 91.000 (91.000)
 * Testing Prec@1 88.940
Epoch: [68/80][0/250]	LR: 0.001	Time 0.215 (0.215)	Data 0.193 (0.193)	Loss 0.1159 (0.1159)	Prec@1 96.500 (96.500)
Epoch: [68/80][100/250]	LR: 0.001	Time 0.034 (0.042)	Data 0.021 (0.027)	Loss 0.1177 (0.1098)	Prec@1 96.500 (96.327)
Epoch: [68/80][200/250]	LR: 0.001	Time 0.034 (0.039)	Data 0.021 (0.025)	Loss 0.0466 (0.1083)	Prec@1 99.000 (96.346)
 * Training Prec@1 96.348
Test: [0/50]	Time 0.100 (0.100)	Loss 0.2750 (0.2750)	Prec@1 91.500 (91.500)
 * Testing Prec@1 88.890
Epoch: [69/80][0/250]	LR: 0.001	Time 0.256 (0.256)	Data 0.235 (0.235)	Loss 0.1213 (0.1213)	Prec@1 96.000 (96.000)
Epoch: [69/80][100/250]	LR: 0.001	Time 0.033 (0.038)	Data 0.020 (0.025)	Loss 0.0977 (0.1083)	Prec@1 97.500 (96.223)
Epoch: [69/80][200/250]	LR: 0.001	Time 0.034 (0.037)	Data 0.020 (0.023)	Loss 0.1264 (0.1076)	Prec@1 96.000 (96.199)
 * Training Prec@1 96.200
Test: [0/50]	Time 0.125 (0.125)	Loss 0.2639 (0.2639)	Prec@1 90.500 (90.500)
 * Testing Prec@1 89.050
Epoch: [70/80][0/250]	LR: 0.001	Time 0.262 (0.262)	Data 0.240 (0.240)	Loss 0.0884 (0.0884)	Prec@1 97.500 (97.500)
Epoch: [70/80][100/250]	LR: 0.001	Time 0.036 (0.039)	Data 0.022 (0.024)	Loss 0.0693 (0.1088)	Prec@1 97.000 (96.257)
Epoch: [70/80][200/250]	LR: 0.001	Time 0.040 (0.038)	Data 0.025 (0.024)	Loss 0.0897 (0.1059)	Prec@1 97.000 (96.353)
 * Training Prec@1 96.314
Test: [0/50]	Time 0.131 (0.131)	Loss 0.2716 (0.2716)	Prec@1 91.000 (91.000)
 * Testing Prec@1 88.980
Epoch: [71/80][0/250]	LR: 0.001	Time 0.251 (0.251)	Data 0.233 (0.233)	Loss 0.1198 (0.1198)	Prec@1 94.000 (94.000)
Epoch: [71/80][100/250]	LR: 0.001	Time 0.036 (0.038)	Data 0.023 (0.023)	Loss 0.0938 (0.1085)	Prec@1 98.000 (96.213)
Epoch: [71/80][200/250]	LR: 0.001	Time 0.043 (0.039)	Data 0.030 (0.024)	Loss 0.1249 (0.1078)	Prec@1 95.500 (96.224)
 * Training Prec@1 96.264
Test: [0/50]	Time 0.115 (0.115)	Loss 0.2674 (0.2674)	Prec@1 90.500 (90.500)
 * Testing Prec@1 88.980
Epoch: [72/80][0/250]	LR: 0.001	Time 0.243 (0.243)	Data 0.225 (0.225)	Loss 0.0851 (0.0851)	Prec@1 96.500 (96.500)
Epoch: [72/80][100/250]	LR: 0.001	Time 0.046 (0.040)	Data 0.031 (0.024)	Loss 0.0897 (0.1075)	Prec@1 97.000 (96.277)
Epoch: [72/80][200/250]	LR: 0.001	Time 0.033 (0.038)	Data 0.016 (0.022)	Loss 0.1411 (0.1059)	Prec@1 93.000 (96.346)
 * Training Prec@1 96.356
Test: [0/50]	Time 0.098 (0.098)	Loss 0.2700 (0.2700)	Prec@1 91.000 (91.000)
 * Testing Prec@1 88.900
Epoch: [73/80][0/250]	LR: 0.001	Time 0.232 (0.232)	Data 0.218 (0.218)	Loss 0.1592 (0.1592)	Prec@1 96.000 (96.000)
Epoch: [73/80][100/250]	LR: 0.001	Time 0.034 (0.040)	Data 0.020 (0.025)	Loss 0.1302 (0.1055)	Prec@1 95.000 (96.540)
Epoch: [73/80][200/250]	LR: 0.001	Time 0.039 (0.038)	Data 0.021 (0.023)	Loss 0.1287 (0.1056)	Prec@1 95.000 (96.413)
 * Training Prec@1 96.402
Test: [0/50]	Time 0.122 (0.122)	Loss 0.2697 (0.2697)	Prec@1 91.000 (91.000)
 * Testing Prec@1 88.900
Epoch: [74/80][0/250]	LR: 0.001	Time 0.249 (0.249)	Data 0.231 (0.231)	Loss 0.1281 (0.1281)	Prec@1 96.500 (96.500)
Epoch: [74/80][100/250]	LR: 0.001	Time 0.040 (0.038)	Data 0.026 (0.024)	Loss 0.1036 (0.1089)	Prec@1 96.500 (96.332)
Epoch: [74/80][200/250]	LR: 0.001	Time 0.034 (0.038)	Data 0.023 (0.024)	Loss 0.1103 (0.1054)	Prec@1 95.000 (96.400)
 * Training Prec@1 96.472
Test: [0/50]	Time 0.131 (0.131)	Loss 0.2707 (0.2707)	Prec@1 91.000 (91.000)
 * Testing Prec@1 88.840
Epoch: [75/80][0/250]	LR: 0.001	Time 0.223 (0.223)	Data 0.202 (0.202)	Loss 0.1553 (0.1553)	Prec@1 93.000 (93.000)
Epoch: [75/80][100/250]	LR: 0.001	Time 0.038 (0.038)	Data 0.024 (0.025)	Loss 0.1075 (0.1028)	Prec@1 96.000 (96.500)
Epoch: [75/80][200/250]	LR: 0.001	Time 0.034 (0.039)	Data 0.020 (0.025)	Loss 0.0707 (0.1051)	Prec@1 98.000 (96.343)
 * Training Prec@1 96.284
Test: [0/50]	Time 0.119 (0.119)	Loss 0.2604 (0.2604)	Prec@1 90.500 (90.500)
 * Testing Prec@1 88.910
Epoch: [76/80][0/250]	LR: 0.001	Time 0.219 (0.219)	Data 0.199 (0.199)	Loss 0.2059 (0.2059)	Prec@1 93.500 (93.500)
Epoch: [76/80][100/250]	LR: 0.001	Time 0.038 (0.040)	Data 0.020 (0.025)	Loss 0.0781 (0.1058)	Prec@1 97.500 (96.262)
Epoch: [76/80][200/250]	LR: 0.001	Time 0.035 (0.038)	Data 0.021 (0.023)	Loss 0.1508 (0.1074)	Prec@1 96.000 (96.249)
 * Training Prec@1 96.296
Test: [0/50]	Time 0.140 (0.140)	Loss 0.2641 (0.2641)	Prec@1 91.000 (91.000)
 * Testing Prec@1 88.850
Epoch: [77/80][0/250]	LR: 0.001	Time 0.214 (0.214)	Data 0.192 (0.192)	Loss 0.1020 (0.1020)	Prec@1 96.500 (96.500)
Epoch: [77/80][100/250]	LR: 0.001	Time 0.041 (0.041)	Data 0.027 (0.026)	Loss 0.1338 (0.1062)	Prec@1 95.000 (96.312)
Epoch: [77/80][200/250]	LR: 0.001	Time 0.034 (0.039)	Data 0.019 (0.024)	Loss 0.1356 (0.1034)	Prec@1 95.000 (96.428)
 * Training Prec@1 96.384
Test: [0/50]	Time 0.092 (0.092)	Loss 0.2671 (0.2671)	Prec@1 90.500 (90.500)
 * Testing Prec@1 88.920
Epoch: [78/80][0/250]	LR: 0.001	Time 0.246 (0.246)	Data 0.227 (0.227)	Loss 0.1452 (0.1452)	Prec@1 96.000 (96.000)
Epoch: [78/80][100/250]	LR: 0.001	Time 0.034 (0.038)	Data 0.022 (0.024)	Loss 0.0958 (0.1010)	Prec@1 96.500 (96.495)
Epoch: [78/80][200/250]	LR: 0.001	Time 0.034 (0.037)	Data 0.020 (0.023)	Loss 0.1328 (0.1041)	Prec@1 94.500 (96.423)
 * Training Prec@1 96.452
Test: [0/50]	Time 0.127 (0.127)	Loss 0.2599 (0.2599)	Prec@1 90.500 (90.500)
 * Testing Prec@1 88.950
Epoch: [79/80][0/250]	LR: 0.001	Time 0.262 (0.262)	Data 0.243 (0.243)	Loss 0.0682 (0.0682)	Prec@1 97.500 (97.500)
Epoch: [79/80][100/250]	LR: 0.001	Time 0.038 (0.042)	Data 0.024 (0.027)	Loss 0.0567 (0.1060)	Prec@1 99.000 (96.297)
Epoch: [79/80][200/250]	LR: 0.001	Time 0.034 (0.040)	Data 0.020 (0.025)	Loss 0.0548 (0.1044)	Prec@1 98.500 (96.338)
 * Training Prec@1 96.396
Test: [0/50]	Time 0.139 (0.139)	Loss 0.2659 (0.2659)	Prec@1 90.500 (90.500)
 * Testing Prec@1 88.920
