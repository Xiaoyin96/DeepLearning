Building CIFAR-10 data loader with 1 workers
Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./cifar10/cifar10-data/cifar-10-python.tar.gz
CIFAR-10 training data size: 50000
Files already downloaded and verified
CIFAR-10 testing data size: 10000
=> creating model 'plainnet8'
Epoch: [0/80][0/250]	LR: 0.1	Time 1.978 (1.978)	Data 0.140 (0.140)	Loss 2.3196 (2.3196)	Prec@1 7.500 (7.500)
Epoch: [0/80][100/250]	LR: 0.1	Time 0.034 (0.059)	Data 0.028 (0.034)	Loss 2.0053 (2.1627)	Prec@1 22.500 (17.000)
Epoch: [0/80][200/250]	LR: 0.1	Time 0.035 (0.048)	Data 0.029 (0.032)	Loss 1.8344 (2.0613)	Prec@1 25.500 (20.396)
 * Training Prec@1 21.754
Test: [0/50]	Time 0.223 (0.223)	Loss 1.9882 (1.9882)	Prec@1 17.500 (17.500)
 * Testing Prec@1 20.920
Epoch: [1/80][0/250]	LR: 0.1	Time 0.171 (0.171)	Data 0.162 (0.162)	Loss 1.8214 (1.8214)	Prec@1 27.000 (27.000)
Epoch: [1/80][100/250]	LR: 0.1	Time 0.033 (0.042)	Data 0.027 (0.035)	Loss 1.8924 (1.8620)	Prec@1 25.000 (29.381)
Epoch: [1/80][200/250]	LR: 0.1	Time 0.033 (0.038)	Data 0.028 (0.032)	Loss 1.6528 (1.8080)	Prec@1 34.000 (31.502)
 * Training Prec@1 32.388
Test: [0/50]	Time 0.147 (0.147)	Loss 1.7192 (1.7192)	Prec@1 36.000 (36.000)
 * Testing Prec@1 36.430
Epoch: [2/80][0/250]	LR: 0.1	Time 0.170 (0.170)	Data 0.161 (0.161)	Loss 1.6149 (1.6149)	Prec@1 34.000 (34.000)
Epoch: [2/80][100/250]	LR: 0.1	Time 0.035 (0.040)	Data 0.029 (0.033)	Loss 1.7093 (1.6771)	Prec@1 35.000 (36.812)
Epoch: [2/80][200/250]	LR: 0.1	Time 0.033 (0.037)	Data 0.027 (0.030)	Loss 1.5200 (1.6539)	Prec@1 45.500 (38.266)
 * Training Prec@1 39.020
Test: [0/50]	Time 0.135 (0.135)	Loss 1.5894 (1.5894)	Prec@1 41.000 (41.000)
 * Testing Prec@1 43.550
Epoch: [3/80][0/250]	LR: 0.1	Time 0.234 (0.234)	Data 0.226 (0.226)	Loss 1.6932 (1.6932)	Prec@1 42.000 (42.000)
Epoch: [3/80][100/250]	LR: 0.1	Time 0.033 (0.036)	Data 0.028 (0.029)	Loss 1.3646 (1.5436)	Prec@1 49.000 (43.738)
Epoch: [3/80][200/250]	LR: 0.1	Time 0.033 (0.035)	Data 0.026 (0.029)	Loss 1.3773 (1.5030)	Prec@1 53.000 (45.035)
 * Training Prec@1 45.418
Test: [0/50]	Time 0.105 (0.105)	Loss 1.5191 (1.5191)	Prec@1 48.000 (48.000)
 * Testing Prec@1 45.910
Epoch: [4/80][0/250]	LR: 0.1	Time 0.252 (0.252)	Data 0.243 (0.243)	Loss 1.4242 (1.4242)	Prec@1 46.500 (46.500)
Epoch: [4/80][100/250]	LR: 0.1	Time 0.034 (0.037)	Data 0.027 (0.030)	Loss 1.4585 (1.4069)	Prec@1 41.000 (48.881)
Epoch: [4/80][200/250]	LR: 0.1	Time 0.032 (0.035)	Data 0.026 (0.028)	Loss 1.3550 (1.3937)	Prec@1 54.000 (49.480)
 * Training Prec@1 50.192
Test: [0/50]	Time 0.146 (0.146)	Loss 1.3618 (1.3618)	Prec@1 50.500 (50.500)
 * Testing Prec@1 53.340
Epoch: [5/80][0/250]	LR: 0.1	Time 0.249 (0.249)	Data 0.239 (0.239)	Loss 1.2787 (1.2787)	Prec@1 47.000 (47.000)
Epoch: [5/80][100/250]	LR: 0.1	Time 0.032 (0.035)	Data 0.026 (0.028)	Loss 1.1716 (1.2771)	Prec@1 61.000 (54.574)
Epoch: [5/80][200/250]	LR: 0.1	Time 0.034 (0.034)	Data 0.028 (0.027)	Loss 1.2059 (1.2686)	Prec@1 58.000 (54.799)
 * Training Prec@1 55.212
Test: [0/50]	Time 0.110 (0.110)	Loss 1.2813 (1.2813)	Prec@1 55.000 (55.000)
 * Testing Prec@1 57.850
Epoch: [6/80][0/250]	LR: 0.1	Time 0.250 (0.250)	Data 0.239 (0.239)	Loss 1.3356 (1.3356)	Prec@1 50.000 (50.000)
Epoch: [6/80][100/250]	LR: 0.1	Time 0.036 (0.036)	Data 0.029 (0.029)	Loss 1.2606 (1.1898)	Prec@1 54.500 (57.569)
Epoch: [6/80][200/250]	LR: 0.1	Time 0.030 (0.035)	Data 0.024 (0.028)	Loss 1.1207 (1.1837)	Prec@1 59.500 (58.117)
 * Training Prec@1 58.432
Test: [0/50]	Time 0.108 (0.108)	Loss 1.1197 (1.1197)	Prec@1 59.000 (59.000)
 * Testing Prec@1 60.190
Epoch: [7/80][0/250]	LR: 0.1	Time 0.226 (0.226)	Data 0.216 (0.216)	Loss 1.1719 (1.1719)	Prec@1 57.000 (57.000)
Epoch: [7/80][100/250]	LR: 0.1	Time 0.032 (0.035)	Data 0.026 (0.029)	Loss 1.1186 (1.1182)	Prec@1 65.500 (60.708)
Epoch: [7/80][200/250]	LR: 0.1	Time 0.033 (0.034)	Data 0.027 (0.028)	Loss 1.0115 (1.0881)	Prec@1 66.000 (61.863)
 * Training Prec@1 62.192
Test: [0/50]	Time 0.092 (0.092)	Loss 1.0294 (1.0294)	Prec@1 62.000 (62.000)
 * Testing Prec@1 62.410
Epoch: [8/80][0/250]	LR: 0.1	Time 0.226 (0.226)	Data 0.218 (0.218)	Loss 1.1387 (1.1387)	Prec@1 59.500 (59.500)
Epoch: [8/80][100/250]	LR: 0.1	Time 0.035 (0.040)	Data 0.029 (0.033)	Loss 1.0458 (1.0247)	Prec@1 62.500 (64.564)
Epoch: [8/80][200/250]	LR: 0.1	Time 0.035 (0.038)	Data 0.028 (0.031)	Loss 1.1603 (1.0131)	Prec@1 58.000 (65.085)
 * Training Prec@1 65.104
Test: [0/50]	Time 0.126 (0.126)	Loss 1.0060 (1.0060)	Prec@1 63.000 (63.000)
 * Testing Prec@1 65.610
Epoch: [9/80][0/250]	LR: 0.1	Time 0.240 (0.240)	Data 0.233 (0.233)	Loss 0.8697 (0.8697)	Prec@1 70.000 (70.000)
Epoch: [9/80][100/250]	LR: 0.1	Time 0.034 (0.041)	Data 0.028 (0.035)	Loss 1.0175 (0.9746)	Prec@1 61.000 (66.030)
Epoch: [9/80][200/250]	LR: 0.1	Time 0.032 (0.040)	Data 0.027 (0.033)	Loss 0.8713 (0.9665)	Prec@1 68.000 (66.326)
 * Training Prec@1 66.656
Test: [0/50]	Time 0.126 (0.126)	Loss 0.9189 (0.9189)	Prec@1 65.000 (65.000)
 * Testing Prec@1 68.410
Epoch: [10/80][0/250]	LR: 0.1	Time 0.183 (0.183)	Data 0.174 (0.174)	Loss 0.9291 (0.9291)	Prec@1 71.000 (71.000)
Epoch: [10/80][100/250]	LR: 0.1	Time 0.036 (0.038)	Data 0.029 (0.031)	Loss 0.8936 (0.9278)	Prec@1 70.000 (67.837)
Epoch: [10/80][200/250]	LR: 0.1	Time 0.033 (0.036)	Data 0.027 (0.030)	Loss 0.8148 (0.9277)	Prec@1 71.000 (67.933)
 * Training Prec@1 68.134
Test: [0/50]	Time 0.126 (0.126)	Loss 0.9328 (0.9328)	Prec@1 68.000 (68.000)
 * Testing Prec@1 69.070
Epoch: [11/80][0/250]	LR: 0.1	Time 0.179 (0.179)	Data 0.168 (0.168)	Loss 1.0413 (1.0413)	Prec@1 66.500 (66.500)
Epoch: [11/80][100/250]	LR: 0.1	Time 0.034 (0.041)	Data 0.029 (0.034)	Loss 0.9525 (0.8792)	Prec@1 67.500 (70.292)
Epoch: [11/80][200/250]	LR: 0.1	Time 0.034 (0.038)	Data 0.028 (0.032)	Loss 0.8462 (0.8812)	Prec@1 71.500 (69.968)
 * Training Prec@1 70.072
Test: [0/50]	Time 0.133 (0.133)	Loss 0.9142 (0.9142)	Prec@1 69.000 (69.000)
 * Testing Prec@1 68.660
Epoch: [12/80][0/250]	LR: 0.1	Time 0.174 (0.174)	Data 0.164 (0.164)	Loss 0.8850 (0.8850)	Prec@1 69.500 (69.500)
Epoch: [12/80][100/250]	LR: 0.1	Time 0.037 (0.039)	Data 0.031 (0.032)	Loss 1.0108 (0.8516)	Prec@1 65.000 (70.634)
Epoch: [12/80][200/250]	LR: 0.1	Time 0.033 (0.036)	Data 0.027 (0.030)	Loss 0.8642 (0.8482)	Prec@1 70.000 (70.816)
 * Training Prec@1 70.670
Test: [0/50]	Time 0.136 (0.136)	Loss 0.9126 (0.9126)	Prec@1 70.000 (70.000)
 * Testing Prec@1 70.730
Epoch: [13/80][0/250]	LR: 0.1	Time 0.196 (0.196)	Data 0.185 (0.185)	Loss 0.9151 (0.9151)	Prec@1 71.000 (71.000)
Epoch: [13/80][100/250]	LR: 0.1	Time 0.033 (0.035)	Data 0.026 (0.028)	Loss 0.7148 (0.8220)	Prec@1 75.000 (72.198)
Epoch: [13/80][200/250]	LR: 0.1	Time 0.033 (0.034)	Data 0.027 (0.027)	Loss 0.8495 (0.8379)	Prec@1 71.500 (71.555)
 * Training Prec@1 71.578
Test: [0/50]	Time 0.120 (0.120)	Loss 0.7803 (0.7803)	Prec@1 73.000 (73.000)
 * Testing Prec@1 73.160
Epoch: [14/80][0/250]	LR: 0.1	Time 0.195 (0.195)	Data 0.184 (0.184)	Loss 0.7086 (0.7086)	Prec@1 74.500 (74.500)
Epoch: [14/80][100/250]	LR: 0.1	Time 0.033 (0.035)	Data 0.028 (0.029)	Loss 0.7060 (0.8104)	Prec@1 74.500 (72.193)
Epoch: [14/80][200/250]	LR: 0.1	Time 0.034 (0.034)	Data 0.027 (0.028)	Loss 0.9926 (0.7992)	Prec@1 70.500 (72.721)
 * Training Prec@1 72.774
Test: [0/50]	Time 0.097 (0.097)	Loss 0.8130 (0.8130)	Prec@1 71.000 (71.000)
 * Testing Prec@1 73.790
Epoch: [15/80][0/250]	LR: 0.1	Time 0.268 (0.268)	Data 0.257 (0.257)	Loss 0.8466 (0.8466)	Prec@1 72.000 (72.000)
Epoch: [15/80][100/250]	LR: 0.1	Time 0.033 (0.043)	Data 0.027 (0.036)	Loss 0.8457 (0.7712)	Prec@1 66.500 (73.460)
Epoch: [15/80][200/250]	LR: 0.1	Time 0.033 (0.038)	Data 0.027 (0.031)	Loss 0.8471 (0.7906)	Prec@1 73.000 (73.022)
 * Training Prec@1 72.910
Test: [0/50]	Time 0.139 (0.139)	Loss 0.7816 (0.7816)	Prec@1 73.500 (73.500)
 * Testing Prec@1 72.360
Epoch: [16/80][0/250]	LR: 0.1	Time 0.151 (0.151)	Data 0.140 (0.140)	Loss 0.8063 (0.8063)	Prec@1 71.500 (71.500)
Epoch: [16/80][100/250]	LR: 0.1	Time 0.032 (0.036)	Data 0.025 (0.029)	Loss 0.8454 (0.7625)	Prec@1 72.500 (74.307)
Epoch: [16/80][200/250]	LR: 0.1	Time 0.034 (0.034)	Data 0.026 (0.027)	Loss 0.6830 (0.7729)	Prec@1 72.500 (73.649)
 * Training Prec@1 73.612
Test: [0/50]	Time 0.126 (0.126)	Loss 0.8983 (0.8983)	Prec@1 70.000 (70.000)
 * Testing Prec@1 72.570
Epoch: [17/80][0/250]	LR: 0.1	Time 0.195 (0.195)	Data 0.184 (0.184)	Loss 0.7310 (0.7310)	Prec@1 72.500 (72.500)
Epoch: [17/80][100/250]	LR: 0.1	Time 0.033 (0.035)	Data 0.027 (0.028)	Loss 0.7795 (0.7433)	Prec@1 73.000 (74.911)
Epoch: [17/80][200/250]	LR: 0.1	Time 0.033 (0.034)	Data 0.027 (0.027)	Loss 0.8576 (0.7485)	Prec@1 67.500 (74.498)
 * Training Prec@1 74.558
Test: [0/50]	Time 0.109 (0.109)	Loss 0.7695 (0.7695)	Prec@1 75.000 (75.000)
 * Testing Prec@1 74.390
Epoch: [18/80][0/250]	LR: 0.1	Time 0.253 (0.253)	Data 0.243 (0.243)	Loss 0.8297 (0.8297)	Prec@1 69.500 (69.500)
Epoch: [18/80][100/250]	LR: 0.1	Time 0.039 (0.039)	Data 0.033 (0.033)	Loss 0.7563 (0.7287)	Prec@1 74.000 (74.955)
Epoch: [18/80][200/250]	LR: 0.1	Time 0.032 (0.036)	Data 0.027 (0.030)	Loss 0.9414 (0.7426)	Prec@1 71.500 (74.711)
 * Training Prec@1 74.722
Test: [0/50]	Time 0.127 (0.127)	Loss 0.7702 (0.7702)	Prec@1 70.000 (70.000)
 * Testing Prec@1 75.100
Epoch: [19/80][0/250]	LR: 0.1	Time 0.275 (0.275)	Data 0.267 (0.267)	Loss 0.6679 (0.6679)	Prec@1 78.500 (78.500)
Epoch: [19/80][100/250]	LR: 0.1	Time 0.035 (0.038)	Data 0.028 (0.031)	Loss 0.8499 (0.7235)	Prec@1 69.500 (75.297)
Epoch: [19/80][200/250]	LR: 0.1	Time 0.034 (0.036)	Data 0.028 (0.029)	Loss 0.6361 (0.7313)	Prec@1 77.500 (75.107)
 * Training Prec@1 75.058
Test: [0/50]	Time 0.121 (0.121)	Loss 0.8156 (0.8156)	Prec@1 72.500 (72.500)
 * Testing Prec@1 75.290
Epoch: [20/80][0/250]	LR: 0.1	Time 0.189 (0.189)	Data 0.178 (0.178)	Loss 0.5649 (0.5649)	Prec@1 84.000 (84.000)
Epoch: [20/80][100/250]	LR: 0.1	Time 0.036 (0.039)	Data 0.031 (0.032)	Loss 0.8001 (0.7287)	Prec@1 71.500 (75.114)
Epoch: [20/80][200/250]	LR: 0.1	Time 0.033 (0.037)	Data 0.027 (0.031)	Loss 0.6895 (0.7323)	Prec@1 73.500 (75.107)
 * Training Prec@1 75.136
Test: [0/50]	Time 0.131 (0.131)	Loss 0.8025 (0.8025)	Prec@1 72.500 (72.500)
 * Testing Prec@1 74.080
Epoch: [21/80][0/250]	LR: 0.1	Time 0.252 (0.252)	Data 0.242 (0.242)	Loss 0.6916 (0.6916)	Prec@1 76.000 (76.000)
Epoch: [21/80][100/250]	LR: 0.1	Time 0.035 (0.040)	Data 0.029 (0.034)	Loss 0.6760 (0.7273)	Prec@1 76.000 (75.381)
Epoch: [21/80][200/250]	LR: 0.1	Time 0.034 (0.037)	Data 0.028 (0.030)	Loss 0.7103 (0.7172)	Prec@1 77.500 (75.669)
 * Training Prec@1 75.766
Test: [0/50]	Time 0.126 (0.126)	Loss 0.8254 (0.8254)	Prec@1 75.500 (75.500)
 * Testing Prec@1 74.700
Epoch: [22/80][0/250]	LR: 0.1	Time 0.147 (0.147)	Data 0.137 (0.137)	Loss 0.7065 (0.7065)	Prec@1 75.000 (75.000)
Epoch: [22/80][100/250]	LR: 0.1	Time 0.033 (0.034)	Data 0.026 (0.028)	Loss 0.7737 (0.7003)	Prec@1 74.500 (76.530)
Epoch: [22/80][200/250]	LR: 0.1	Time 0.033 (0.034)	Data 0.027 (0.027)	Loss 1.0022 (0.7050)	Prec@1 69.000 (76.281)
 * Training Prec@1 76.164
Test: [0/50]	Time 0.100 (0.100)	Loss 0.8764 (0.8764)	Prec@1 75.500 (75.500)
 * Testing Prec@1 76.080
Epoch: [23/80][0/250]	LR: 0.1	Time 0.185 (0.185)	Data 0.175 (0.175)	Loss 0.6729 (0.6729)	Prec@1 78.000 (78.000)
Epoch: [23/80][100/250]	LR: 0.1	Time 0.048 (0.040)	Data 0.041 (0.034)	Loss 0.7531 (0.7030)	Prec@1 75.500 (76.366)
Epoch: [23/80][200/250]	LR: 0.1	Time 0.036 (0.038)	Data 0.029 (0.031)	Loss 0.6586 (0.6964)	Prec@1 79.000 (76.343)
 * Training Prec@1 76.322
Test: [0/50]	Time 0.128 (0.128)	Loss 0.8352 (0.8352)	Prec@1 71.500 (71.500)
 * Testing Prec@1 74.400
Epoch: [24/80][0/250]	LR: 0.1	Time 0.149 (0.149)	Data 0.138 (0.138)	Loss 0.7409 (0.7409)	Prec@1 77.000 (77.000)
Epoch: [24/80][100/250]	LR: 0.1	Time 0.032 (0.034)	Data 0.025 (0.027)	Loss 0.7739 (0.6801)	Prec@1 73.000 (76.960)
Epoch: [24/80][200/250]	LR: 0.1	Time 0.035 (0.034)	Data 0.029 (0.027)	Loss 0.8597 (0.6901)	Prec@1 70.500 (76.507)
 * Training Prec@1 76.530
Test: [0/50]	Time 0.101 (0.101)	Loss 0.8803 (0.8803)	Prec@1 73.500 (73.500)
 * Testing Prec@1 76.530
Epoch: [25/80][0/250]	LR: 0.1	Time 0.266 (0.266)	Data 0.256 (0.256)	Loss 0.6820 (0.6820)	Prec@1 78.500 (78.500)
Epoch: [25/80][100/250]	LR: 0.1	Time 0.036 (0.040)	Data 0.030 (0.033)	Loss 0.6789 (0.6691)	Prec@1 77.000 (77.302)
Epoch: [25/80][200/250]	LR: 0.1	Time 0.034 (0.037)	Data 0.028 (0.030)	Loss 0.6538 (0.6712)	Prec@1 77.000 (77.149)
 * Training Prec@1 77.096
Test: [0/50]	Time 0.133 (0.133)	Loss 0.7488 (0.7488)	Prec@1 77.500 (77.500)
 * Testing Prec@1 78.200
Epoch: [26/80][0/250]	LR: 0.1	Time 0.231 (0.231)	Data 0.223 (0.223)	Loss 0.5378 (0.5378)	Prec@1 80.500 (80.500)
Epoch: [26/80][100/250]	LR: 0.1	Time 0.044 (0.040)	Data 0.037 (0.033)	Loss 0.6171 (0.6622)	Prec@1 77.500 (77.728)
Epoch: [26/80][200/250]	LR: 0.1	Time 0.032 (0.037)	Data 0.026 (0.030)	Loss 0.6316 (0.6766)	Prec@1 80.500 (77.055)
 * Training Prec@1 77.152
Test: [0/50]	Time 0.134 (0.134)	Loss 0.8260 (0.8260)	Prec@1 74.500 (74.500)
 * Testing Prec@1 75.220
Epoch: [27/80][0/250]	LR: 0.1	Time 0.179 (0.179)	Data 0.169 (0.169)	Loss 0.6890 (0.6890)	Prec@1 75.500 (75.500)
Epoch: [27/80][100/250]	LR: 0.1	Time 0.034 (0.035)	Data 0.029 (0.029)	Loss 0.5835 (0.6628)	Prec@1 77.000 (77.554)
Epoch: [27/80][200/250]	LR: 0.1	Time 0.035 (0.035)	Data 0.028 (0.029)	Loss 0.6727 (0.6667)	Prec@1 75.000 (77.552)
 * Training Prec@1 77.574
Test: [0/50]	Time 0.099 (0.099)	Loss 0.7794 (0.7794)	Prec@1 72.500 (72.500)
 * Testing Prec@1 75.710
Epoch: [28/80][0/250]	LR: 0.1	Time 0.258 (0.258)	Data 0.249 (0.249)	Loss 0.7008 (0.7008)	Prec@1 74.000 (74.000)
Epoch: [28/80][100/250]	LR: 0.1	Time 0.034 (0.039)	Data 0.028 (0.032)	Loss 0.6703 (0.6645)	Prec@1 77.500 (77.446)
Epoch: [28/80][200/250]	LR: 0.1	Time 0.032 (0.036)	Data 0.026 (0.030)	Loss 0.8698 (0.6668)	Prec@1 73.000 (77.470)
 * Training Prec@1 77.530
Test: [0/50]	Time 0.133 (0.133)	Loss 0.7789 (0.7789)	Prec@1 76.500 (76.500)
 * Testing Prec@1 77.190
Epoch: [29/80][0/250]	LR: 0.1	Time 0.149 (0.149)	Data 0.139 (0.139)	Loss 0.6407 (0.6407)	Prec@1 76.000 (76.000)
Epoch: [29/80][100/250]	LR: 0.1	Time 0.034 (0.037)	Data 0.029 (0.031)	Loss 0.7384 (0.6621)	Prec@1 73.000 (77.738)
Epoch: [29/80][200/250]	LR: 0.1	Time 0.032 (0.035)	Data 0.026 (0.029)	Loss 0.8651 (0.6713)	Prec@1 70.000 (77.289)
 * Training Prec@1 77.406
Test: [0/50]	Time 0.129 (0.129)	Loss 0.8356 (0.8356)	Prec@1 75.500 (75.500)
 * Testing Prec@1 75.050
Epoch: [30/80][0/250]	LR: 0.1	Time 0.155 (0.155)	Data 0.144 (0.144)	Loss 0.7317 (0.7317)	Prec@1 74.500 (74.500)
Epoch: [30/80][100/250]	LR: 0.1	Time 0.036 (0.039)	Data 0.031 (0.033)	Loss 0.7107 (0.6436)	Prec@1 76.500 (78.431)
Epoch: [30/80][200/250]	LR: 0.1	Time 0.034 (0.037)	Data 0.029 (0.031)	Loss 0.5642 (0.6509)	Prec@1 80.000 (78.201)
 * Training Prec@1 78.414
Test: [0/50]	Time 0.133 (0.133)	Loss 0.7986 (0.7986)	Prec@1 76.500 (76.500)
 * Testing Prec@1 77.120
Epoch: [31/80][0/250]	LR: 0.1	Time 0.220 (0.220)	Data 0.211 (0.211)	Loss 0.7004 (0.7004)	Prec@1 73.500 (73.500)
Epoch: [31/80][100/250]	LR: 0.1	Time 0.045 (0.042)	Data 0.038 (0.035)	Loss 0.6968 (0.6382)	Prec@1 77.500 (78.485)
Epoch: [31/80][200/250]	LR: 0.1	Time 0.030 (0.037)	Data 0.025 (0.031)	Loss 0.6729 (0.6378)	Prec@1 77.000 (78.644)
 * Training Prec@1 78.526
Test: [0/50]	Time 0.129 (0.129)	Loss 0.7152 (0.7152)	Prec@1 76.500 (76.500)
 * Testing Prec@1 77.350
Epoch: [32/80][0/250]	LR: 0.1	Time 0.120 (0.120)	Data 0.111 (0.111)	Loss 0.5207 (0.5207)	Prec@1 83.000 (83.000)
Epoch: [32/80][100/250]	LR: 0.1	Time 0.032 (0.035)	Data 0.026 (0.029)	Loss 0.6194 (0.6486)	Prec@1 79.000 (78.134)
Epoch: [32/80][200/250]	LR: 0.1	Time 0.034 (0.036)	Data 0.028 (0.029)	Loss 0.6117 (0.6372)	Prec@1 82.000 (78.338)
 * Training Prec@1 78.376
Test: [0/50]	Time 0.097 (0.097)	Loss 0.6760 (0.6760)	Prec@1 76.500 (76.500)
 * Testing Prec@1 77.850
Epoch: [33/80][0/250]	LR: 0.1	Time 0.121 (0.121)	Data 0.111 (0.111)	Loss 0.5276 (0.5276)	Prec@1 83.000 (83.000)
Epoch: [33/80][100/250]	LR: 0.1	Time 0.044 (0.041)	Data 0.037 (0.034)	Loss 0.6315 (0.6517)	Prec@1 78.500 (77.995)
Epoch: [33/80][200/250]	LR: 0.1	Time 0.033 (0.039)	Data 0.027 (0.032)	Loss 0.7414 (0.6493)	Prec@1 75.500 (78.271)
 * Training Prec@1 78.294
Test: [0/50]	Time 0.125 (0.125)	Loss 0.7451 (0.7451)	Prec@1 78.500 (78.500)
 * Testing Prec@1 78.160
Epoch: [34/80][0/250]	LR: 0.1	Time 0.123 (0.123)	Data 0.113 (0.113)	Loss 0.5379 (0.5379)	Prec@1 85.500 (85.500)
Epoch: [34/80][100/250]	LR: 0.1	Time 0.038 (0.040)	Data 0.032 (0.033)	Loss 0.7002 (0.6358)	Prec@1 75.500 (78.520)
Epoch: [34/80][200/250]	LR: 0.1	Time 0.030 (0.038)	Data 0.024 (0.031)	Loss 0.6741 (0.6383)	Prec@1 76.500 (78.410)
 * Training Prec@1 78.430
Test: [0/50]	Time 0.136 (0.136)	Loss 0.7207 (0.7207)	Prec@1 79.000 (79.000)
 * Testing Prec@1 77.110
Epoch: [35/80][0/250]	LR: 0.1	Time 0.176 (0.176)	Data 0.166 (0.166)	Loss 0.5393 (0.5393)	Prec@1 82.000 (82.000)
Epoch: [35/80][100/250]	LR: 0.1	Time 0.033 (0.036)	Data 0.026 (0.029)	Loss 0.7204 (0.6394)	Prec@1 77.500 (78.455)
Epoch: [35/80][200/250]	LR: 0.1	Time 0.034 (0.034)	Data 0.028 (0.028)	Loss 0.5861 (0.6340)	Prec@1 78.500 (78.560)
 * Training Prec@1 78.700
Test: [0/50]	Time 0.099 (0.099)	Loss 0.8463 (0.8463)	Prec@1 73.000 (73.000)
 * Testing Prec@1 76.910
Epoch: [36/80][0/250]	LR: 0.1	Time 0.159 (0.159)	Data 0.148 (0.148)	Loss 0.5040 (0.5040)	Prec@1 83.500 (83.500)
Epoch: [36/80][100/250]	LR: 0.1	Time 0.034 (0.035)	Data 0.029 (0.028)	Loss 0.4484 (0.6189)	Prec@1 85.000 (78.970)
Epoch: [36/80][200/250]	LR: 0.1	Time 0.032 (0.035)	Data 0.027 (0.028)	Loss 0.6169 (0.6281)	Prec@1 79.000 (78.689)
 * Training Prec@1 78.678
Test: [0/50]	Time 0.104 (0.104)	Loss 0.6883 (0.6883)	Prec@1 78.500 (78.500)
 * Testing Prec@1 77.400
Epoch: [37/80][0/250]	LR: 0.1	Time 0.253 (0.253)	Data 0.243 (0.243)	Loss 0.5023 (0.5023)	Prec@1 85.000 (85.000)
Epoch: [37/80][100/250]	LR: 0.1	Time 0.033 (0.036)	Data 0.026 (0.030)	Loss 0.6603 (0.6253)	Prec@1 79.000 (78.515)
Epoch: [37/80][200/250]	LR: 0.1	Time 0.032 (0.034)	Data 0.025 (0.028)	Loss 0.5703 (0.6279)	Prec@1 80.000 (78.607)
 * Training Prec@1 78.528
Test: [0/50]	Time 0.098 (0.098)	Loss 0.8246 (0.8246)	Prec@1 74.500 (74.500)
 * Testing Prec@1 75.480
Epoch: [38/80][0/250]	LR: 0.1	Time 0.127 (0.127)	Data 0.116 (0.116)	Loss 0.5919 (0.5919)	Prec@1 82.000 (82.000)
Epoch: [38/80][100/250]	LR: 0.1	Time 0.032 (0.034)	Data 0.025 (0.027)	Loss 0.6743 (0.6095)	Prec@1 75.000 (79.480)
Epoch: [38/80][200/250]	LR: 0.1	Time 0.035 (0.033)	Data 0.028 (0.026)	Loss 0.6812 (0.6123)	Prec@1 77.000 (79.440)
 * Training Prec@1 79.246
Test: [0/50]	Time 0.097 (0.097)	Loss 0.7917 (0.7917)	Prec@1 78.000 (78.000)
 * Testing Prec@1 76.990
Epoch: [39/80][0/250]	LR: 0.1	Time 0.126 (0.126)	Data 0.114 (0.114)	Loss 0.5476 (0.5476)	Prec@1 81.500 (81.500)
Epoch: [39/80][100/250]	LR: 0.1	Time 0.035 (0.034)	Data 0.028 (0.027)	Loss 0.6162 (0.6239)	Prec@1 80.500 (79.045)
Epoch: [39/80][200/250]	LR: 0.1	Time 0.033 (0.035)	Data 0.026 (0.028)	Loss 0.6513 (0.6109)	Prec@1 78.000 (79.271)
 * Training Prec@1 79.184
Test: [0/50]	Time 0.129 (0.129)	Loss 0.8552 (0.8552)	Prec@1 76.000 (76.000)
 * Testing Prec@1 75.870
Epoch: [40/80][0/250]	LR: 0.01	Time 0.139 (0.139)	Data 0.128 (0.128)	Loss 0.7283 (0.7283)	Prec@1 75.000 (75.000)
Epoch: [40/80][100/250]	LR: 0.01	Time 0.033 (0.034)	Data 0.028 (0.028)	Loss 0.5635 (0.5213)	Prec@1 79.000 (82.158)
Epoch: [40/80][200/250]	LR: 0.01	Time 0.032 (0.034)	Data 0.025 (0.027)	Loss 0.3399 (0.5020)	Prec@1 87.500 (82.970)
 * Training Prec@1 83.196
Test: [0/50]	Time 0.101 (0.101)	Loss 0.6922 (0.6922)	Prec@1 79.000 (79.000)
 * Testing Prec@1 81.860
Epoch: [41/80][0/250]	LR: 0.01	Time 0.115 (0.115)	Data 0.105 (0.105)	Loss 0.4939 (0.4939)	Prec@1 85.000 (85.000)
Epoch: [41/80][100/250]	LR: 0.01	Time 0.033 (0.034)	Data 0.027 (0.027)	Loss 0.4507 (0.4610)	Prec@1 83.000 (84.446)
Epoch: [41/80][200/250]	LR: 0.01	Time 0.033 (0.035)	Data 0.026 (0.029)	Loss 0.4515 (0.4620)	Prec@1 84.500 (84.453)
 * Training Prec@1 84.506
Test: [0/50]	Time 0.142 (0.142)	Loss 0.7254 (0.7254)	Prec@1 78.500 (78.500)
 * Testing Prec@1 82.130
Epoch: [42/80][0/250]	LR: 0.01	Time 0.127 (0.127)	Data 0.116 (0.116)	Loss 0.4679 (0.4679)	Prec@1 83.000 (83.000)
Epoch: [42/80][100/250]	LR: 0.01	Time 0.035 (0.040)	Data 0.028 (0.033)	Loss 0.4365 (0.4410)	Prec@1 82.000 (85.035)
Epoch: [42/80][200/250]	LR: 0.01	Time 0.044 (0.039)	Data 0.037 (0.032)	Loss 0.4093 (0.4410)	Prec@1 85.000 (84.908)
 * Training Prec@1 84.842
Test: [0/50]	Time 0.141 (0.141)	Loss 0.7225 (0.7225)	Prec@1 79.500 (79.500)
 * Testing Prec@1 82.150
Epoch: [43/80][0/250]	LR: 0.01	Time 0.281 (0.281)	Data 0.271 (0.271)	Loss 0.4761 (0.4761)	Prec@1 81.000 (81.000)
Epoch: [43/80][100/250]	LR: 0.01	Time 0.035 (0.043)	Data 0.028 (0.037)	Loss 0.4389 (0.4411)	Prec@1 86.500 (84.792)
Epoch: [43/80][200/250]	LR: 0.01	Time 0.029 (0.039)	Data 0.023 (0.032)	Loss 0.4898 (0.4406)	Prec@1 83.500 (84.983)
 * Training Prec@1 84.972
Test: [0/50]	Time 0.127 (0.127)	Loss 0.6904 (0.6904)	Prec@1 81.500 (81.500)
 * Testing Prec@1 82.430
Epoch: [44/80][0/250]	LR: 0.01	Time 0.265 (0.265)	Data 0.255 (0.255)	Loss 0.4327 (0.4327)	Prec@1 82.500 (82.500)
Epoch: [44/80][100/250]	LR: 0.01	Time 0.047 (0.041)	Data 0.041 (0.034)	Loss 0.3719 (0.4227)	Prec@1 84.500 (85.243)
Epoch: [44/80][200/250]	LR: 0.01	Time 0.033 (0.038)	Data 0.027 (0.031)	Loss 0.4167 (0.4305)	Prec@1 85.500 (85.070)
 * Training Prec@1 85.120
Test: [0/50]	Time 0.116 (0.116)	Loss 0.6679 (0.6679)	Prec@1 82.000 (82.000)
 * Testing Prec@1 82.230
Epoch: [45/80][0/250]	LR: 0.01	Time 0.153 (0.153)	Data 0.142 (0.142)	Loss 0.4413 (0.4413)	Prec@1 85.000 (85.000)
Epoch: [45/80][100/250]	LR: 0.01	Time 0.032 (0.035)	Data 0.025 (0.028)	Loss 0.4128 (0.4362)	Prec@1 87.500 (85.129)
Epoch: [45/80][200/250]	LR: 0.01	Time 0.040 (0.034)	Data 0.034 (0.027)	Loss 0.3156 (0.4314)	Prec@1 89.500 (85.226)
 * Training Prec@1 85.244
Test: [0/50]	Time 0.094 (0.094)	Loss 0.6811 (0.6811)	Prec@1 81.000 (81.000)
 * Testing Prec@1 82.850
Epoch: [46/80][0/250]	LR: 0.01	Time 0.265 (0.265)	Data 0.254 (0.254)	Loss 0.4421 (0.4421)	Prec@1 87.000 (87.000)
Epoch: [46/80][100/250]	LR: 0.01	Time 0.032 (0.036)	Data 0.026 (0.029)	Loss 0.5275 (0.4289)	Prec@1 83.000 (85.376)
Epoch: [46/80][200/250]	LR: 0.01	Time 0.034 (0.035)	Data 0.027 (0.028)	Loss 0.3831 (0.4223)	Prec@1 87.000 (85.664)
 * Training Prec@1 85.554
Test: [0/50]	Time 0.102 (0.102)	Loss 0.7373 (0.7373)	Prec@1 77.500 (77.500)
 * Testing Prec@1 82.680
Epoch: [47/80][0/250]	LR: 0.01	Time 0.251 (0.251)	Data 0.240 (0.240)	Loss 0.3367 (0.3367)	Prec@1 88.500 (88.500)
Epoch: [47/80][100/250]	LR: 0.01	Time 0.032 (0.035)	Data 0.026 (0.028)	Loss 0.3439 (0.4201)	Prec@1 89.000 (85.663)
Epoch: [47/80][200/250]	LR: 0.01	Time 0.033 (0.034)	Data 0.027 (0.027)	Loss 0.4637 (0.4181)	Prec@1 84.500 (85.711)
 * Training Prec@1 85.686
Test: [0/50]	Time 0.094 (0.094)	Loss 0.7125 (0.7125)	Prec@1 79.500 (79.500)
 * Testing Prec@1 82.780
Epoch: [48/80][0/250]	LR: 0.01	Time 0.119 (0.119)	Data 0.109 (0.109)	Loss 0.5065 (0.5065)	Prec@1 83.000 (83.000)
Epoch: [48/80][100/250]	LR: 0.01	Time 0.034 (0.038)	Data 0.028 (0.031)	Loss 0.4217 (0.4181)	Prec@1 85.500 (85.574)
Epoch: [48/80][200/250]	LR: 0.01	Time 0.034 (0.035)	Data 0.026 (0.029)	Loss 0.3714 (0.4165)	Prec@1 88.000 (85.639)
 * Training Prec@1 85.708
Test: [0/50]	Time 0.145 (0.145)	Loss 0.7476 (0.7476)	Prec@1 80.000 (80.000)
 * Testing Prec@1 82.720
Epoch: [49/80][0/250]	LR: 0.01	Time 0.173 (0.173)	Data 0.163 (0.163)	Loss 0.4789 (0.4789)	Prec@1 85.500 (85.500)
Epoch: [49/80][100/250]	LR: 0.01	Time 0.033 (0.036)	Data 0.026 (0.030)	Loss 0.3926 (0.4200)	Prec@1 87.000 (85.653)
Epoch: [49/80][200/250]	LR: 0.01	Time 0.039 (0.035)	Data 0.033 (0.028)	Loss 0.4464 (0.4173)	Prec@1 83.000 (85.677)
 * Training Prec@1 85.746
Test: [0/50]	Time 0.097 (0.097)	Loss 0.6796 (0.6796)	Prec@1 81.500 (81.500)
 * Testing Prec@1 82.910
Epoch: [50/80][0/250]	LR: 0.01	Time 0.290 (0.290)	Data 0.279 (0.279)	Loss 0.5161 (0.5161)	Prec@1 82.500 (82.500)
Epoch: [50/80][100/250]	LR: 0.01	Time 0.034 (0.039)	Data 0.028 (0.032)	Loss 0.5297 (0.4137)	Prec@1 83.500 (85.837)
Epoch: [50/80][200/250]	LR: 0.01	Time 0.033 (0.036)	Data 0.027 (0.030)	Loss 0.4318 (0.4086)	Prec@1 85.000 (85.968)
 * Training Prec@1 86.038
Test: [0/50]	Time 0.136 (0.136)	Loss 0.6418 (0.6418)	Prec@1 82.500 (82.500)
 * Testing Prec@1 83.130
Epoch: [51/80][0/250]	LR: 0.01	Time 0.268 (0.268)	Data 0.258 (0.258)	Loss 0.4167 (0.4167)	Prec@1 86.500 (86.500)
Epoch: [51/80][100/250]	LR: 0.01	Time 0.034 (0.038)	Data 0.028 (0.032)	Loss 0.3681 (0.3969)	Prec@1 86.500 (86.584)
Epoch: [51/80][200/250]	LR: 0.01	Time 0.034 (0.038)	Data 0.027 (0.032)	Loss 0.4008 (0.4019)	Prec@1 83.000 (86.259)
 * Training Prec@1 86.186
Test: [0/50]	Time 0.123 (0.123)	Loss 0.6728 (0.6728)	Prec@1 81.500 (81.500)
 * Testing Prec@1 82.680
Epoch: [52/80][0/250]	LR: 0.01	Time 0.120 (0.120)	Data 0.111 (0.111)	Loss 0.4563 (0.4563)	Prec@1 85.500 (85.500)
Epoch: [52/80][100/250]	LR: 0.01	Time 0.036 (0.040)	Data 0.026 (0.033)	Loss 0.4599 (0.4038)	Prec@1 85.500 (86.228)
Epoch: [52/80][200/250]	LR: 0.01	Time 0.033 (0.037)	Data 0.026 (0.030)	Loss 0.3866 (0.4002)	Prec@1 87.000 (86.428)
 * Training Prec@1 86.218
Test: [0/50]	Time 0.121 (0.121)	Loss 0.6518 (0.6518)	Prec@1 81.500 (81.500)
 * Testing Prec@1 83.320
Epoch: [53/80][0/250]	LR: 0.01	Time 0.158 (0.158)	Data 0.147 (0.147)	Loss 0.3896 (0.3896)	Prec@1 85.000 (85.000)
Epoch: [53/80][100/250]	LR: 0.01	Time 0.053 (0.039)	Data 0.045 (0.032)	Loss 0.3031 (0.3962)	Prec@1 89.000 (86.149)
Epoch: [53/80][200/250]	LR: 0.01	Time 0.030 (0.039)	Data 0.025 (0.032)	Loss 0.3159 (0.3985)	Prec@1 89.000 (86.149)
 * Training Prec@1 86.072
Test: [0/50]	Time 0.131 (0.131)	Loss 0.6665 (0.6665)	Prec@1 80.000 (80.000)
 * Testing Prec@1 83.060
Epoch: [54/80][0/250]	LR: 0.01	Time 0.150 (0.150)	Data 0.139 (0.139)	Loss 0.3926 (0.3926)	Prec@1 86.500 (86.500)
Epoch: [54/80][100/250]	LR: 0.01	Time 0.036 (0.040)	Data 0.030 (0.033)	Loss 0.4037 (0.3991)	Prec@1 84.500 (86.371)
Epoch: [54/80][200/250]	LR: 0.01	Time 0.035 (0.037)	Data 0.029 (0.031)	Loss 0.4226 (0.3983)	Prec@1 85.500 (86.410)
 * Training Prec@1 86.436
Test: [0/50]	Time 0.137 (0.137)	Loss 0.6540 (0.6540)	Prec@1 80.500 (80.500)
 * Testing Prec@1 83.290
Epoch: [55/80][0/250]	LR: 0.01	Time 0.139 (0.139)	Data 0.128 (0.128)	Loss 0.3973 (0.3973)	Prec@1 86.000 (86.000)
Epoch: [55/80][100/250]	LR: 0.01	Time 0.046 (0.035)	Data 0.038 (0.028)	Loss 0.5424 (0.3957)	Prec@1 78.500 (86.104)
Epoch: [55/80][200/250]	LR: 0.01	Time 0.036 (0.036)	Data 0.029 (0.029)	Loss 0.3382 (0.3967)	Prec@1 87.000 (86.276)
 * Training Prec@1 86.380
Test: [0/50]	Time 0.120 (0.120)	Loss 0.6629 (0.6629)	Prec@1 80.000 (80.000)
 * Testing Prec@1 82.910
Epoch: [56/80][0/250]	LR: 0.01	Time 0.250 (0.250)	Data 0.241 (0.241)	Loss 0.4714 (0.4714)	Prec@1 84.500 (84.500)
Epoch: [56/80][100/250]	LR: 0.01	Time 0.033 (0.038)	Data 0.027 (0.032)	Loss 0.4700 (0.3952)	Prec@1 86.500 (86.386)
Epoch: [56/80][200/250]	LR: 0.01	Time 0.029 (0.036)	Data 0.024 (0.030)	Loss 0.3690 (0.3921)	Prec@1 85.000 (86.637)
 * Training Prec@1 86.572
Test: [0/50]	Time 0.127 (0.127)	Loss 0.6417 (0.6417)	Prec@1 81.500 (81.500)
 * Testing Prec@1 83.450
Epoch: [57/80][0/250]	LR: 0.01	Time 0.252 (0.252)	Data 0.241 (0.241)	Loss 0.3305 (0.3305)	Prec@1 91.000 (91.000)
Epoch: [57/80][100/250]	LR: 0.01	Time 0.032 (0.035)	Data 0.026 (0.028)	Loss 0.4536 (0.3823)	Prec@1 83.500 (86.911)
Epoch: [57/80][200/250]	LR: 0.01	Time 0.036 (0.036)	Data 0.029 (0.029)	Loss 0.2945 (0.3851)	Prec@1 93.000 (86.923)
 * Training Prec@1 86.830
Test: [0/50]	Time 0.144 (0.144)	Loss 0.6060 (0.6060)	Prec@1 81.000 (81.000)
 * Testing Prec@1 83.480
Epoch: [58/80][0/250]	LR: 0.01	Time 0.241 (0.241)	Data 0.232 (0.232)	Loss 0.2822 (0.2822)	Prec@1 88.500 (88.500)
Epoch: [58/80][100/250]	LR: 0.01	Time 0.033 (0.036)	Data 0.026 (0.029)	Loss 0.4511 (0.3813)	Prec@1 85.000 (86.931)
Epoch: [58/80][200/250]	LR: 0.01	Time 0.032 (0.035)	Data 0.027 (0.028)	Loss 0.2973 (0.3900)	Prec@1 90.500 (86.709)
 * Training Prec@1 86.610
Test: [0/50]	Time 0.098 (0.098)	Loss 0.6386 (0.6386)	Prec@1 81.000 (81.000)
 * Testing Prec@1 83.540
Epoch: [59/80][0/250]	LR: 0.01	Time 0.280 (0.280)	Data 0.270 (0.270)	Loss 0.3603 (0.3603)	Prec@1 85.500 (85.500)
Epoch: [59/80][100/250]	LR: 0.01	Time 0.033 (0.036)	Data 0.026 (0.029)	Loss 0.2960 (0.3741)	Prec@1 89.500 (87.099)
Epoch: [59/80][200/250]	LR: 0.01	Time 0.032 (0.035)	Data 0.027 (0.029)	Loss 0.5172 (0.3838)	Prec@1 82.000 (86.791)
 * Training Prec@1 86.656
Test: [0/50]	Time 0.104 (0.104)	Loss 0.6449 (0.6449)	Prec@1 81.000 (81.000)
 * Testing Prec@1 83.430
Epoch: [60/80][0/250]	LR: 0.001	Time 0.162 (0.162)	Data 0.151 (0.151)	Loss 0.3399 (0.3399)	Prec@1 91.000 (91.000)
Epoch: [60/80][100/250]	LR: 0.001	Time 0.034 (0.036)	Data 0.027 (0.030)	Loss 0.4037 (0.3811)	Prec@1 89.000 (87.139)
Epoch: [60/80][200/250]	LR: 0.001	Time 0.032 (0.035)	Data 0.026 (0.028)	Loss 0.2903 (0.3756)	Prec@1 90.500 (87.100)
 * Training Prec@1 87.236
Test: [0/50]	Time 0.102 (0.102)	Loss 0.6185 (0.6185)	Prec@1 82.000 (82.000)
 * Testing Prec@1 83.800
Epoch: [61/80][0/250]	LR: 0.001	Time 0.239 (0.239)	Data 0.229 (0.229)	Loss 0.3245 (0.3245)	Prec@1 88.500 (88.500)
Epoch: [61/80][100/250]	LR: 0.001	Time 0.034 (0.035)	Data 0.028 (0.029)	Loss 0.3264 (0.3649)	Prec@1 88.000 (87.386)
Epoch: [61/80][200/250]	LR: 0.001	Time 0.033 (0.034)	Data 0.027 (0.028)	Loss 0.4273 (0.3671)	Prec@1 84.500 (87.336)
 * Training Prec@1 87.402
Test: [0/50]	Time 0.135 (0.135)	Loss 0.6302 (0.6302)	Prec@1 81.000 (81.000)
 * Testing Prec@1 83.750
Epoch: [62/80][0/250]	LR: 0.001	Time 0.169 (0.169)	Data 0.159 (0.159)	Loss 0.4414 (0.4414)	Prec@1 84.000 (84.000)
Epoch: [62/80][100/250]	LR: 0.001	Time 0.036 (0.035)	Data 0.030 (0.029)	Loss 0.4406 (0.3731)	Prec@1 83.500 (86.847)
Epoch: [62/80][200/250]	LR: 0.001	Time 0.034 (0.034)	Data 0.026 (0.028)	Loss 0.3880 (0.3690)	Prec@1 86.000 (87.092)
 * Training Prec@1 87.224
Test: [0/50]	Time 0.101 (0.101)	Loss 0.6322 (0.6322)	Prec@1 80.500 (80.500)
 * Testing Prec@1 83.790
Epoch: [63/80][0/250]	LR: 0.001	Time 0.143 (0.143)	Data 0.132 (0.132)	Loss 0.3012 (0.3012)	Prec@1 89.000 (89.000)
Epoch: [63/80][100/250]	LR: 0.001	Time 0.033 (0.034)	Data 0.027 (0.028)	Loss 0.3348 (0.3660)	Prec@1 89.000 (87.144)
Epoch: [63/80][200/250]	LR: 0.001	Time 0.034 (0.034)	Data 0.028 (0.027)	Loss 0.3296 (0.3676)	Prec@1 88.500 (87.351)
 * Training Prec@1 87.278
Test: [0/50]	Time 0.103 (0.103)	Loss 0.6389 (0.6389)	Prec@1 80.000 (80.000)
 * Testing Prec@1 83.760
Epoch: [64/80][0/250]	LR: 0.001	Time 0.127 (0.127)	Data 0.116 (0.116)	Loss 0.2451 (0.2451)	Prec@1 91.000 (91.000)
Epoch: [64/80][100/250]	LR: 0.001	Time 0.035 (0.038)	Data 0.028 (0.031)	Loss 0.3176 (0.3747)	Prec@1 90.500 (87.406)
Epoch: [64/80][200/250]	LR: 0.001	Time 0.033 (0.036)	Data 0.026 (0.030)	Loss 0.3080 (0.3705)	Prec@1 89.000 (87.336)
 * Training Prec@1 87.372
Test: [0/50]	Time 0.134 (0.134)	Loss 0.6233 (0.6233)	Prec@1 81.500 (81.500)
 * Testing Prec@1 83.790
Epoch: [65/80][0/250]	LR: 0.001	Time 0.253 (0.253)	Data 0.243 (0.243)	Loss 0.3959 (0.3959)	Prec@1 87.500 (87.500)
Epoch: [65/80][100/250]	LR: 0.001	Time 0.034 (0.035)	Data 0.026 (0.028)	Loss 0.3048 (0.3670)	Prec@1 90.500 (87.515)
Epoch: [65/80][200/250]	LR: 0.001	Time 0.032 (0.034)	Data 0.025 (0.028)	Loss 0.2892 (0.3678)	Prec@1 91.500 (87.507)
 * Training Prec@1 87.536
Test: [0/50]	Time 0.131 (0.131)	Loss 0.6178 (0.6178)	Prec@1 81.500 (81.500)
 * Testing Prec@1 83.830
Epoch: [66/80][0/250]	LR: 0.001	Time 0.247 (0.247)	Data 0.237 (0.237)	Loss 0.4243 (0.4243)	Prec@1 87.000 (87.000)
Epoch: [66/80][100/250]	LR: 0.001	Time 0.032 (0.037)	Data 0.025 (0.031)	Loss 0.3281 (0.3678)	Prec@1 90.000 (87.347)
Epoch: [66/80][200/250]	LR: 0.001	Time 0.032 (0.035)	Data 0.026 (0.029)	Loss 0.2944 (0.3695)	Prec@1 92.000 (87.383)
 * Training Prec@1 87.392
Test: [0/50]	Time 0.137 (0.137)	Loss 0.6160 (0.6160)	Prec@1 81.000 (81.000)
 * Testing Prec@1 84.000
Epoch: [67/80][0/250]	LR: 0.001	Time 0.282 (0.282)	Data 0.268 (0.268)	Loss 0.3810 (0.3810)	Prec@1 89.000 (89.000)
Epoch: [67/80][100/250]	LR: 0.001	Time 0.034 (0.037)	Data 0.027 (0.031)	Loss 0.3242 (0.3644)	Prec@1 88.500 (87.574)
Epoch: [67/80][200/250]	LR: 0.001	Time 0.032 (0.035)	Data 0.025 (0.029)	Loss 0.4072 (0.3627)	Prec@1 88.500 (87.647)
 * Training Prec@1 87.570
Test: [0/50]	Time 0.135 (0.135)	Loss 0.6138 (0.6138)	Prec@1 81.500 (81.500)
 * Testing Prec@1 83.950
Epoch: [68/80][0/250]	LR: 0.001	Time 0.153 (0.153)	Data 0.143 (0.143)	Loss 0.2510 (0.2510)	Prec@1 91.000 (91.000)
Epoch: [68/80][100/250]	LR: 0.001	Time 0.034 (0.034)	Data 0.027 (0.027)	Loss 0.3839 (0.3609)	Prec@1 87.500 (87.752)
Epoch: [68/80][200/250]	LR: 0.001	Time 0.033 (0.034)	Data 0.026 (0.027)	Loss 0.3706 (0.3596)	Prec@1 87.000 (87.639)
 * Training Prec@1 87.620
Test: [0/50]	Time 0.137 (0.137)	Loss 0.6306 (0.6306)	Prec@1 78.500 (78.500)
 * Testing Prec@1 83.970
Epoch: [69/80][0/250]	LR: 0.001	Time 0.144 (0.144)	Data 0.133 (0.133)	Loss 0.3765 (0.3765)	Prec@1 85.500 (85.500)
Epoch: [69/80][100/250]	LR: 0.001	Time 0.034 (0.034)	Data 0.027 (0.027)	Loss 0.3521 (0.3624)	Prec@1 88.500 (87.718)
Epoch: [69/80][200/250]	LR: 0.001	Time 0.034 (0.034)	Data 0.028 (0.027)	Loss 0.4150 (0.3635)	Prec@1 85.500 (87.592)
 * Training Prec@1 87.546
Test: [0/50]	Time 0.119 (0.119)	Loss 0.6173 (0.6173)	Prec@1 80.500 (80.500)
 * Testing Prec@1 84.020
Epoch: [70/80][0/250]	LR: 0.001	Time 0.246 (0.246)	Data 0.236 (0.236)	Loss 0.3723 (0.3723)	Prec@1 86.500 (86.500)
Epoch: [70/80][100/250]	LR: 0.001	Time 0.032 (0.035)	Data 0.025 (0.028)	Loss 0.3256 (0.3523)	Prec@1 89.000 (87.941)
Epoch: [70/80][200/250]	LR: 0.001	Time 0.031 (0.034)	Data 0.025 (0.028)	Loss 0.3363 (0.3574)	Prec@1 85.500 (87.739)
 * Training Prec@1 87.640
Test: [0/50]	Time 0.145 (0.145)	Loss 0.6176 (0.6176)	Prec@1 80.000 (80.000)
 * Testing Prec@1 83.950
Epoch: [71/80][0/250]	LR: 0.001	Time 0.163 (0.163)	Data 0.153 (0.153)	Loss 0.3205 (0.3205)	Prec@1 89.000 (89.000)
Epoch: [71/80][100/250]	LR: 0.001	Time 0.030 (0.034)	Data 0.024 (0.028)	Loss 0.5143 (0.3633)	Prec@1 83.000 (87.441)
Epoch: [71/80][200/250]	LR: 0.001	Time 0.035 (0.034)	Data 0.029 (0.027)	Loss 0.3130 (0.3604)	Prec@1 88.500 (87.557)
 * Training Prec@1 87.526
Test: [0/50]	Time 0.108 (0.108)	Loss 0.6136 (0.6136)	Prec@1 82.000 (82.000)
 * Testing Prec@1 84.010
Epoch: [72/80][0/250]	LR: 0.001	Time 0.184 (0.184)	Data 0.173 (0.173)	Loss 0.2463 (0.2463)	Prec@1 93.000 (93.000)
Epoch: [72/80][100/250]	LR: 0.001	Time 0.036 (0.036)	Data 0.029 (0.030)	Loss 0.2624 (0.3551)	Prec@1 91.500 (87.946)
Epoch: [72/80][200/250]	LR: 0.001	Time 0.032 (0.035)	Data 0.026 (0.028)	Loss 0.3138 (0.3602)	Prec@1 89.000 (87.759)
 * Training Prec@1 87.624
Test: [0/50]	Time 0.131 (0.131)	Loss 0.6087 (0.6087)	Prec@1 81.000 (81.000)
 * Testing Prec@1 84.020
Epoch: [73/80][0/250]	LR: 0.001	Time 0.149 (0.149)	Data 0.138 (0.138)	Loss 0.4527 (0.4527)	Prec@1 86.000 (86.000)
Epoch: [73/80][100/250]	LR: 0.001	Time 0.033 (0.035)	Data 0.027 (0.028)	Loss 0.3225 (0.3684)	Prec@1 91.500 (87.416)
Epoch: [73/80][200/250]	LR: 0.001	Time 0.033 (0.034)	Data 0.027 (0.027)	Loss 0.3021 (0.3654)	Prec@1 89.500 (87.438)
 * Training Prec@1 87.416
Test: [0/50]	Time 0.127 (0.127)	Loss 0.6149 (0.6149)	Prec@1 80.000 (80.000)
 * Testing Prec@1 84.040
Epoch: [74/80][0/250]	LR: 0.001	Time 0.217 (0.217)	Data 0.208 (0.208)	Loss 0.3899 (0.3899)	Prec@1 89.000 (89.000)
Epoch: [74/80][100/250]	LR: 0.001	Time 0.033 (0.035)	Data 0.027 (0.029)	Loss 0.3993 (0.3703)	Prec@1 87.000 (87.312)
Epoch: [74/80][200/250]	LR: 0.001	Time 0.033 (0.034)	Data 0.027 (0.028)	Loss 0.3073 (0.3676)	Prec@1 92.000 (87.229)
 * Training Prec@1 87.318
Test: [0/50]	Time 0.116 (0.116)	Loss 0.6231 (0.6231)	Prec@1 80.500 (80.500)
 * Testing Prec@1 83.830
Epoch: [75/80][0/250]	LR: 0.001	Time 0.250 (0.250)	Data 0.240 (0.240)	Loss 0.4303 (0.4303)	Prec@1 85.500 (85.500)
Epoch: [75/80][100/250]	LR: 0.001	Time 0.032 (0.037)	Data 0.026 (0.030)	Loss 0.3722 (0.3662)	Prec@1 88.500 (87.490)
Epoch: [75/80][200/250]	LR: 0.001	Time 0.032 (0.035)	Data 0.026 (0.028)	Loss 0.4124 (0.3633)	Prec@1 87.500 (87.507)
 * Training Prec@1 87.622
Test: [0/50]	Time 0.138 (0.138)	Loss 0.6229 (0.6229)	Prec@1 81.000 (81.000)
 * Testing Prec@1 84.060
Epoch: [76/80][0/250]	LR: 0.001	Time 0.148 (0.148)	Data 0.138 (0.138)	Loss 0.2782 (0.2782)	Prec@1 92.000 (92.000)
Epoch: [76/80][100/250]	LR: 0.001	Time 0.033 (0.039)	Data 0.026 (0.033)	Loss 0.3335 (0.3602)	Prec@1 88.500 (87.728)
Epoch: [76/80][200/250]	LR: 0.001	Time 0.034 (0.036)	Data 0.027 (0.030)	Loss 0.2851 (0.3609)	Prec@1 90.000 (87.624)
 * Training Prec@1 87.598
Test: [0/50]	Time 0.119 (0.119)	Loss 0.6198 (0.6198)	Prec@1 81.000 (81.000)
 * Testing Prec@1 84.010
Epoch: [77/80][0/250]	LR: 0.001	Time 0.132 (0.132)	Data 0.121 (0.121)	Loss 0.4133 (0.4133)	Prec@1 85.000 (85.000)
Epoch: [77/80][100/250]	LR: 0.001	Time 0.032 (0.034)	Data 0.025 (0.027)	Loss 0.3205 (0.3559)	Prec@1 88.500 (87.609)
Epoch: [77/80][200/250]	LR: 0.001	Time 0.033 (0.034)	Data 0.027 (0.027)	Loss 0.3261 (0.3575)	Prec@1 88.500 (87.634)
 * Training Prec@1 87.636
Test: [0/50]	Time 0.104 (0.104)	Loss 0.6232 (0.6232)	Prec@1 80.500 (80.500)
 * Testing Prec@1 84.090
Epoch: [78/80][0/250]	LR: 0.001	Time 0.266 (0.266)	Data 0.254 (0.254)	Loss 0.3217 (0.3217)	Prec@1 90.000 (90.000)
Epoch: [78/80][100/250]	LR: 0.001	Time 0.032 (0.040)	Data 0.026 (0.034)	Loss 0.3768 (0.3664)	Prec@1 87.500 (87.574)
Epoch: [78/80][200/250]	LR: 0.001	Time 0.033 (0.037)	Data 0.026 (0.030)	Loss 0.4613 (0.3587)	Prec@1 81.000 (87.754)
 * Training Prec@1 87.626
Test: [0/50]	Time 0.135 (0.135)	Loss 0.6249 (0.6249)	Prec@1 79.500 (79.500)
 * Testing Prec@1 84.090
Epoch: [79/80][0/250]	LR: 0.001	Time 0.188 (0.188)	Data 0.177 (0.177)	Loss 0.4329 (0.4329)	Prec@1 84.000 (84.000)
Epoch: [79/80][100/250]	LR: 0.001	Time 0.033 (0.035)	Data 0.027 (0.029)	Loss 0.2976 (0.3684)	Prec@1 89.500 (87.327)
Epoch: [79/80][200/250]	LR: 0.001	Time 0.035 (0.034)	Data 0.028 (0.028)	Loss 0.3810 (0.3635)	Prec@1 86.000 (87.483)
 * Training Prec@1 87.534
Test: [0/50]	Time 0.131 (0.131)	Loss 0.6229 (0.6229)	Prec@1 80.000 (80.000)
 * Testing Prec@1 84.070
